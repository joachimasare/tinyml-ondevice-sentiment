{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joachimasare/tinyml-ondevice-sentiment/blob/main/Channel_Pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaPo_-QMBNrs"
      },
      "source": [
        "# Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPrfePAkcela",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3293f2d0-069c-4ede-c5aa-ab8b601a1f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "# imports needed for pytorch tinyBERT project\n",
        "\n",
        "!pip install scikit-learn\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "from sklearn.metrics import accuracy_score\n",
        "import copy\n",
        "from typing import Union, List\n",
        "\n",
        "import csv\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources and Links\n",
        "\n",
        "\n",
        "*   [TinyBERT github](https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT)\n",
        "*   [BERT-base code ](https://github.com/google-research/bert?tab=readme-ov-file)\n",
        "*   [TinyBERT pretrained model](https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D)\n",
        "*   [Dataset](https://github.com/nyu-mll/GLUE-baselines.git)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bugjukHuJo87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading dataset\n",
        "\n",
        "!git clone https://github.com/nyu-mll/GLUE-baselines.git\n",
        "!python GLUE-baselines/download_glue_data.py --data_dir /content --tasks SST"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb2T5LkNu925",
        "outputId": "d95191b5-e717-47a9-daa3-b532ba4419f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GLUE-baselines'...\n",
            "remote: Enumerating objects: 891, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 891 (delta 1), reused 3 (delta 1), pack-reused 886 (from 1)\u001b[K\n",
            "Receiving objects: 100% (891/891), 1.48 MiB | 6.55 MiB/s, done.\n",
            "Resolving deltas: 100% (610/610), done.\n",
            "Downloading and extracting SST...\n",
            "\tCompleted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx1E5KApfdXa",
        "outputId": "ae25ac89-5d10-4565-d35a-a515017da02c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Pretrained-Language-Model'...\n",
            "remote: Enumerating objects: 1253, done.\u001b[K\n",
            "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 1253 (delta 173), reused 120 (delta 119), pack-reused 973 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1253/1253), 29.72 MiB | 17.21 MiB/s, done.\n",
            "Resolving deltas: 100% (540/540), done.\n"
          ]
        }
      ],
      "source": [
        "# download tinyBERT source code and install dependencies\n",
        "\n",
        "!git clone https://github.com/huawei-noah/Pretrained-Language-Model.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QWSrTgBBfgAc",
        "outputId": "08946227-bf34-410c-815c-7ee406e05649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Pretrained-Language-Model/TinyBERT\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.66.6)\n",
            "Collecting boto3 (from -r requirements.txt (line 4))\n",
            "  Downloading boto3-1.35.81-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.5.1+cu121)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.13.2)\n",
            "Collecting botocore<1.36.0,>=1.35.81 (from boto3->-r requirements.txt (line 4))\n",
            "  Downloading botocore-1.35.81-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->-r requirements.txt (line 4))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->-r requirements.txt (line 4))\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->-r requirements.txt (line 8)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->-r requirements.txt (line 8)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->-r requirements.txt (line 8)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->-r requirements.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->-r requirements.txt (line 8)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->-r requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.1->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy>=0.14.0->-r requirements.txt (line 9)) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn->-r requirements.txt (line 10)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn->-r requirements.txt (line 10)) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.81->boto3->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 10)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 10)) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.1->-r requirements.txt (line 8)) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.81->boto3->-r requirements.txt (line 4)) (1.17.0)\n",
            "Downloading boto3-1.35.81-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.81-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.35.81 botocore-1.35.81 jmespath-1.0.1 s3transfer-0.10.4\n"
          ]
        }
      ],
      "source": [
        "%cd Pretrained-Language-Model/TinyBERT\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q309iaPHCFu1",
        "outputId": "8f1c2cbd-63fd-4380-dac7-c796e208b548"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a333e587150>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "SEED = 42\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE8Mu8y-B1nn",
        "outputId": "08fab4dd-e39f-4cb9-95c9-d2322c408793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing torchprofile...\n",
            "Installing fast-pytorch-kmeans...\n",
            "All required packages have been successfully installed!\n"
          ]
        }
      ],
      "source": [
        "print('Installing torchprofile...')\n",
        "!pip install torchprofile 1>/dev/null\n",
        "print('Installing fast-pytorch-kmeans...')\n",
        "! pip install fast-pytorch-kmeans 1>/dev/null\n",
        "print('All required packages have been successfully installed!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchprofile import profile_macs\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "zO_GNsQrxdn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XYShlwDgr81S",
        "outputId": "00521308-a812-4b49-f8d1-c6503092e920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-14 20:05:44--  https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.207, 64.233.181.207, 142.251.183.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 404261442 (386M) [application/zip]\n",
            "Saving to: ‘cased_L-12_H-768_A-12.zip’\n",
            "\n",
            "cased_L-12_H-768_A- 100%[===================>] 385.53M  74.1MB/s    in 4.3s    \n",
            "\n",
            "2024-12-14 20:05:48 (88.7 MB/s) - ‘cased_L-12_H-768_A-12.zip’ saved [404261442/404261442]\n",
            "\n",
            "Archive:  cased_L-12_H-768_A-12.zip\n",
            "   creating: cased_L-12_H-768_A-12/\n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: cased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_config.json  \n"
          ]
        }
      ],
      "source": [
        "# downloading BERT-base code\n",
        "\n",
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
        "!unzip cased_L-12_H-768_A-12.zip\n",
        "!cp cased_L-12_H-768_A-12/bert_config.json cased_L-12_H-768_A-12/config.json # must rename bert_config to config\n",
        "\n",
        "BERT_BASE_DIR = 'cased_L-12_H-768_A-12'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIQxKQHloj0B",
        "outputId": "508678f0-7a68-4056-8c6f-587b7a2dada8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TinyBERT_General_4L_312D'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Total 24 (delta 0), reused 0 (delta 0), pack-reused 24 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (24/24), 111.20 KiB | 3.83 MiB/s, done.\n",
            "Filtering content: 100% (2/2), 114.58 MiB | 23.45 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "# cloning TinyBert pretrained models\n",
        "\n",
        "!git clone https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D\n",
        "\n",
        "STUDENT_CONFIG_DIR = '/content/Pretrained-Language-Model/TinyBERT/TinyBERT_General_4L_312D'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HomAbFzXBSQV"
      },
      "outputs": [],
      "source": [
        "def get_model_size(model: nn.Module, data_width=32):\n",
        "    \"\"\"\n",
        "    calculate the model size in bits\n",
        "    :param data_width: #bits per element\n",
        "    \"\"\"\n",
        "    num_elements = 0\n",
        "    for param in model.parameters():\n",
        "        num_elements += param.numel()\n",
        "    return num_elements * data_width\n",
        "\n",
        "Byte = 8\n",
        "KiB = 1024 * Byte\n",
        "MiB = 1024 * KiB\n",
        "GiB = 1024 * MiB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformer.modeling import TinyBertForPreTraining, BertModel, TinyBertForSequenceClassification"
      ],
      "metadata": {
        "id": "DLjCsuCyxlBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_86yuIcDFV2r"
      },
      "outputs": [],
      "source": [
        "# Setting up student model\n",
        "\n",
        "STUDENT_CONFIG_DIR = '/content/Pretrained-Language-Model/TinyBERT/TinyBERT_General_4L_312D'\n",
        "BERT_BASE_DIR = '/content/Pretrained-Language-Model/TinyBERT/cased_L-12_H-768_A-12'\n",
        "\n",
        "student_model = TinyBertForPreTraining.from_scratch(STUDENT_CONFIG_DIR)\n",
        "teacher_model = BertModel.from_scratch(BERT_BASE_DIR)\n",
        "\n",
        "num_labels = 2\n",
        "student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1skFFNfCo2pm",
        "outputId": "649e016d-5323-4b1b-b887-81dec3d660a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student model size:  55.661231994628906 MiB\n",
            "Teacher model size:  413.1708984375 MiB\n"
          ]
        }
      ],
      "source": [
        "# Getting sizes of models\n",
        "\n",
        "student_model_size = get_model_size(student_model)\n",
        "teacher_model_size = get_model_size(teacher_model)\n",
        "\n",
        "print(\"Student model size: \", student_model_size/MiB, \"MiB\")\n",
        "print(\"Teacher model size: \", teacher_model_size/MiB, \"MiB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbnT-JiUIdXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e2c86e5-5005-4cb4-90da-895e082f65b0",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyBertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 312)\n",
              "      (token_type_embeddings): Embedding(2, 312)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-3): 4 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=312, out_features=2, bias=True)\n",
              "  (fit_dense): Linear(in_features=312, out_features=768, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "student_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n, m in student_model.named_modules():\n",
        "    if isinstance(m, nn.Linear):\n",
        "        print(n)\n",
        "        print(m.weight.data.shape)"
      ],
      "metadata": {
        "id": "1eTBfQv6Pw1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4908fab5-da24-4ce4-db85-6178d429802a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.encoder.layer.0.attention.self.query\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.0.attention.self.key\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.0.attention.self.value\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.0.attention.output.dense\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.0.intermediate.dense\n",
            "torch.Size([1200, 312])\n",
            "bert.encoder.layer.0.output.dense\n",
            "torch.Size([312, 1200])\n",
            "bert.encoder.layer.1.attention.self.query\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.1.attention.self.key\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.1.attention.self.value\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.1.attention.output.dense\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.1.intermediate.dense\n",
            "torch.Size([1200, 312])\n",
            "bert.encoder.layer.1.output.dense\n",
            "torch.Size([312, 1200])\n",
            "bert.encoder.layer.2.attention.self.query\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.2.attention.self.key\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.2.attention.self.value\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.2.attention.output.dense\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.2.intermediate.dense\n",
            "torch.Size([1200, 312])\n",
            "bert.encoder.layer.2.output.dense\n",
            "torch.Size([312, 1200])\n",
            "bert.encoder.layer.3.attention.self.query\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.3.attention.self.key\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.3.attention.self.value\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.3.attention.output.dense\n",
            "torch.Size([312, 312])\n",
            "bert.encoder.layer.3.intermediate.dense\n",
            "torch.Size([1200, 312])\n",
            "bert.encoder.layer.3.output.dense\n",
            "torch.Size([312, 1200])\n",
            "bert.pooler.dense\n",
            "torch.Size([312, 312])\n",
            "classifier\n",
            "torch.Size([2, 312])\n",
            "fit_dense\n",
            "torch.Size([768, 312])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in student_model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5hmwSv_IF0C",
        "outputId": "22a6d997-d769-4ff8-8e24-be634b513733",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight torch.Size([30522, 312])\n",
            "bert.embeddings.position_embeddings.weight torch.Size([512, 312])\n",
            "bert.embeddings.token_type_embeddings.weight torch.Size([2, 312])\n",
            "bert.embeddings.LayerNorm.weight torch.Size([312])\n",
            "bert.embeddings.LayerNorm.bias torch.Size([312])\n",
            "bert.encoder.layer.0.attention.self.query.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.0.attention.self.query.bias torch.Size([312])\n",
            "bert.encoder.layer.0.attention.self.key.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.0.attention.self.key.bias torch.Size([312])\n",
            "bert.encoder.layer.0.attention.self.value.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.0.attention.self.value.bias torch.Size([312])\n",
            "bert.encoder.layer.0.attention.output.dense.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.0.attention.output.dense.bias torch.Size([312])\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([312])\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([312])\n",
            "bert.encoder.layer.0.intermediate.dense.weight torch.Size([1200, 312])\n",
            "bert.encoder.layer.0.intermediate.dense.bias torch.Size([1200])\n",
            "bert.encoder.layer.0.output.dense.weight torch.Size([312, 1200])\n",
            "bert.encoder.layer.0.output.dense.bias torch.Size([312])\n",
            "bert.encoder.layer.0.output.LayerNorm.weight torch.Size([312])\n",
            "bert.encoder.layer.0.output.LayerNorm.bias torch.Size([312])\n",
            "bert.encoder.layer.1.attention.self.query.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.1.attention.self.query.bias torch.Size([312])\n",
            "bert.encoder.layer.1.attention.self.key.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.1.attention.self.key.bias torch.Size([312])\n",
            "bert.encoder.layer.1.attention.self.value.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.1.attention.self.value.bias torch.Size([312])\n",
            "bert.encoder.layer.1.attention.output.dense.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.1.attention.output.dense.bias torch.Size([312])\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([312])\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([312])\n",
            "bert.encoder.layer.1.intermediate.dense.weight torch.Size([1200, 312])\n",
            "bert.encoder.layer.1.intermediate.dense.bias torch.Size([1200])\n",
            "bert.encoder.layer.1.output.dense.weight torch.Size([312, 1200])\n",
            "bert.encoder.layer.1.output.dense.bias torch.Size([312])\n",
            "bert.encoder.layer.1.output.LayerNorm.weight torch.Size([312])\n",
            "bert.encoder.layer.1.output.LayerNorm.bias torch.Size([312])\n",
            "bert.encoder.layer.2.attention.self.query.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.2.attention.self.query.bias torch.Size([312])\n",
            "bert.encoder.layer.2.attention.self.key.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.2.attention.self.key.bias torch.Size([312])\n",
            "bert.encoder.layer.2.attention.self.value.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.2.attention.self.value.bias torch.Size([312])\n",
            "bert.encoder.layer.2.attention.output.dense.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.2.attention.output.dense.bias torch.Size([312])\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([312])\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([312])\n",
            "bert.encoder.layer.2.intermediate.dense.weight torch.Size([1200, 312])\n",
            "bert.encoder.layer.2.intermediate.dense.bias torch.Size([1200])\n",
            "bert.encoder.layer.2.output.dense.weight torch.Size([312, 1200])\n",
            "bert.encoder.layer.2.output.dense.bias torch.Size([312])\n",
            "bert.encoder.layer.2.output.LayerNorm.weight torch.Size([312])\n",
            "bert.encoder.layer.2.output.LayerNorm.bias torch.Size([312])\n",
            "bert.encoder.layer.3.attention.self.query.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.3.attention.self.query.bias torch.Size([312])\n",
            "bert.encoder.layer.3.attention.self.key.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.3.attention.self.key.bias torch.Size([312])\n",
            "bert.encoder.layer.3.attention.self.value.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.3.attention.self.value.bias torch.Size([312])\n",
            "bert.encoder.layer.3.attention.output.dense.weight torch.Size([312, 312])\n",
            "bert.encoder.layer.3.attention.output.dense.bias torch.Size([312])\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([312])\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([312])\n",
            "bert.encoder.layer.3.intermediate.dense.weight torch.Size([1200, 312])\n",
            "bert.encoder.layer.3.intermediate.dense.bias torch.Size([1200])\n",
            "bert.encoder.layer.3.output.dense.weight torch.Size([312, 1200])\n",
            "bert.encoder.layer.3.output.dense.bias torch.Size([312])\n",
            "bert.encoder.layer.3.output.LayerNorm.weight torch.Size([312])\n",
            "bert.encoder.layer.3.output.LayerNorm.bias torch.Size([312])\n",
            "bert.pooler.dense.weight torch.Size([312, 312])\n",
            "bert.pooler.dense.bias torch.Size([312])\n",
            "classifier.weight torch.Size([2, 312])\n",
            "classifier.bias torch.Size([2])\n",
            "fit_dense.weight torch.Size([768, 312])\n",
            "fit_dense.bias torch.Size([768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Setup"
      ],
      "metadata": {
        "id": "XVTGl7f-0quc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# declaring functions necessary for fine tuning and evaluating\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            label: (Optional) string. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_id, seq_length=None):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.seq_length = seq_length\n",
        "        self.label_id = label_id"
      ],
      "metadata": {
        "id": "zHBMfAg5hlVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataProcessor(object):\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "            lines = []\n",
        "            for line in reader:\n",
        "                if sys.version_info[0] == 2:\n",
        "                    line = list(unicode(cell, 'utf-8') for cell in line)\n",
        "                lines.append(line)\n",
        "            return lines\n",
        "\n",
        "class Sst2Processor(DataProcessor):\n",
        "    \"\"\"Processor for the SST-2 data set (GLUE version).\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
        "\n",
        "    def get_aug_examples(self, data_dir):\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"train_aug.tsv\")), \"aug\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"0\", \"1\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            text_a = line[0]\n",
        "            label = line[1]\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "        return examples\n"
      ],
      "metadata": {
        "id": "Ac7O1wwhhBMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_accuracy(preds, labels):\n",
        "    return (preds == labels).mean()\n",
        "\n",
        "def compute_metrics(task_name, preds, labels):\n",
        "    assert len(preds) == len(labels)\n",
        "    return {\"acc\": simple_accuracy(preds, labels)}\n",
        "\n",
        "# evaluation function based on  task_distill.py --do_eval\n",
        "def evaluate_tinybert(model, task_name, eval_dataloader,\n",
        "            device, output_mode, eval_labels, num_labels):\n",
        "    eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    preds = []\n",
        "\n",
        "    model.eval()\n",
        "    for batch_ in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        batch_ = tuple(t.to(device) for t in batch_)\n",
        "        with torch.no_grad():\n",
        "            input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch_\n",
        "\n",
        "            # ValueError: not enough values to unpack (expected 3, got 2)\n",
        "            # logits, _, _ = model(input_ids, segment_ids, input_mask)\n",
        "            # TODO: what is the model outputting? What\n",
        "            logits, _ , _= model(input_ids, segment_ids, input_mask)\n",
        "\n",
        "\n",
        "        # create eval loss and other metric required by the task\n",
        "        if output_mode == \"classification\":\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            tmp_eval_loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
        "        elif output_mode == \"regression\":\n",
        "            loss_fct = MSELoss()\n",
        "            tmp_eval_loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "\n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "        if len(preds) == 0:\n",
        "            preds.append(logits.detach().cpu().numpy())\n",
        "        else:\n",
        "            preds[0] = np.append(\n",
        "                preds[0], logits.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "\n",
        "    preds = preds[0]\n",
        "    if output_mode == \"classification\":\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "    elif output_mode == \"regression\":\n",
        "        preds = np.squeeze(preds)\n",
        "    result = compute_metrics(task_name, preds, eval_labels.numpy())\n",
        "    result['eval_loss'] = eval_loss\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "output_mode = \"classification\"\n"
      ],
      "metadata": {
        "id": "C1gGXWDvUWj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from task_distill import convert_examples_to_features, get_tensor_data\n",
        "from torch.utils.data import SequentialSampler"
      ],
      "metadata": {
        "id": "anV3YKxwiH9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the evaluation dataloader\n",
        "\n",
        "do_lower_case = False\n",
        "data_dir = '/content/SST-2'\n",
        "processor = Sst2Processor()\n",
        "label_list = processor.get_labels()\n",
        "num_labels = len(label_list)\n",
        "max_seq_length = 128\n",
        "eval_batch_size = 32\n",
        "task_name = \"sst2\"\n",
        "output_mode = \"classification\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)\n",
        "student_model.to(device)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(STUDENT_CONFIG_DIR, do_lower_case=do_lower_case)\n",
        "eval_examples = processor.get_dev_examples(data_dir)\n",
        "eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "eval_data, eval_labels = get_tensor_data(output_mode, eval_features)\n",
        "eval_sampler = SequentialSampler(eval_data)\n",
        "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n"
      ],
      "metadata": {
        "id": "vLAwycTbWOnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculations during evaluation\n",
        "        for batch in dataloader:\n",
        "\n",
        "            # Handle cases where batch might have more than 4 elements\n",
        "            if len(batch) == 4:\n",
        "                input_ids, attention_masks, segment_ids, labels = batch\n",
        "            else:  # Adjust this logic based on your data format\n",
        "                input_ids, attention_masks, segment_ids, labels, *_ = batch\n",
        "                # *_ unpacks the remaining elements to a throwaway variable _\n",
        "\n",
        "            print(input_ids.shape)\n",
        "            print(attention_masks.shape)\n",
        "            print(segment_ids.shape)\n",
        "            print(labels.shape)\n",
        "\n",
        "            input_ids, attention_masks, segment_ids, labels = input_ids.to(device), attention_masks.to(device), segment_ids.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_masks, segment_ids)\n",
        "            _, predicted = torch.max(outputs, 1)  # Get predicted labels\n",
        "\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "3EAnz2X-1xT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetuning"
      ],
      "metadata": {
        "id": "88riz4E7rj9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Do run the Evaluation Setup to run this section"
      ],
      "metadata": {
        "id": "UWEThlaq8G4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_tinybert(\n",
        "    model,\n",
        "    task_name,\n",
        "    train_dataloader,\n",
        "    eval_dataloader,\n",
        "    device,\n",
        "    output_mode,\n",
        "    num_labels,\n",
        "    eval_labels,\n",
        "    optimizer=None,\n",
        "    scheduler=None,\n",
        "    epochs=3\n",
        "):\n",
        "    \"\"\"\n",
        "    Fine-tune a TinyBERT model with training and validation metrics history.\n",
        "\n",
        "    Args:\n",
        "        model: The TinyBERT model to be fine-tuned.\n",
        "        task_name: Name of the task (used for metric computation).\n",
        "        train_dataloader: DataLoader for training data.\n",
        "        eval_dataloader: DataLoader for evaluation data.\n",
        "        device: Device to train on (e.g., 'cpu' or 'cuda').\n",
        "        output_mode: Output mode for the task ('classification' or 'regression').\n",
        "        num_labels: Number of labels for classification tasks.\n",
        "        eval_labels: Ground truth labels for the evaluation set.\n",
        "        optimizer: Optimizer for training (default is AdamW).\n",
        "        scheduler: Learning rate scheduler (optional).\n",
        "        epochs: Number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "        model: The fine-tuned model with a `history` attribute.\n",
        "    \"\"\"\n",
        "    # Initialize optimizer if none is provided\n",
        "    if optimizer is None:\n",
        "        optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    # Initialize or extend model's history attribute\n",
        "    if not hasattr(model, 'history'):\n",
        "        model.history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    # Move model to the specified device\n",
        "    model.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0  # To track total training loss\n",
        "        nb_train_steps = 0  # To count the number of training steps\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Training step\n",
        "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training\")):\n",
        "            # Move each tensor in the batch to the device\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch\n",
        "\n",
        "            # Zero the gradients to prevent accumulation\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            logits, _, _ = model(input_ids, segment_ids, input_mask)\n",
        "\n",
        "            # Compute loss\n",
        "            if output_mode == \"classification\":\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "            elif output_mode == \"regression\":\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "                preds = logits.squeeze()\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown output mode: {output_mode}\")\n",
        "\n",
        "            # Update metrics\n",
        "            if output_mode == \"classification\":\n",
        "                correct_predictions += (preds == label_ids).sum().item()\n",
        "                total_predictions += label_ids.size(0)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update training metrics\n",
        "            total_loss += loss.item()\n",
        "            nb_train_steps += 1\n",
        "\n",
        "        # Adjust learning rate with scheduler (if provided)\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Compute training metrics\n",
        "        avg_train_loss = total_loss / nb_train_steps\n",
        "        train_accuracy = correct_predictions / total_predictions if output_mode == \"classification\" else None\n",
        "        print(f\"Training loss: {avg_train_loss:.4f}\")\n",
        "        if train_accuracy is not None:\n",
        "            print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "        # Evaluate the model\n",
        "        eval_result = evaluate_tinybert(\n",
        "            model, task_name, eval_dataloader, device, output_mode, eval_labels, num_labels\n",
        "        )\n",
        "        avg_val_loss = eval_result['eval_loss']\n",
        "        val_accuracy = eval_result['acc']\n",
        "\n",
        "        # Print validation results\n",
        "        print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Update the model's history\n",
        "        model.history['train_loss'].append(avg_train_loss)\n",
        "        model.history['val_loss'].append(avg_val_loss)\n",
        "        if train_accuracy is not None:\n",
        "            model.history['train_acc'].append(train_accuracy)\n",
        "        model.history['val_acc'].append(val_accuracy)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "fdaqNFbKrlvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the evaluation dataloader\n",
        "\n",
        "do_lower_case = False\n",
        "data_dir = '/content/SST-2'\n",
        "processor = Sst2Processor()\n",
        "label_list = processor.get_labels()\n",
        "num_labels = len(label_list)\n",
        "max_seq_length = 128\n",
        "eval_batch_size = 32\n",
        "train_batch_size = 32\n",
        "task_name = \"sst2\"\n",
        "output_mode = \"classification\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)\n",
        "student_model.to(device)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(STUDENT_CONFIG_DIR, do_lower_case=do_lower_case)\n",
        "eval_examples = processor.get_dev_examples(data_dir)\n",
        "eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "eval_data, eval_labels = get_tensor_data(output_mode, eval_features)\n",
        "eval_sampler = SequentialSampler(eval_data)\n",
        "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
        "\n",
        "train_examples = processor.get_train_examples(data_dir)\n",
        "train_features = convert_examples_to_features(train_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "train_data, train_labels = get_tensor_data(output_mode, train_features)\n",
        "train_sampler = SequentialSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
        "\n",
        "# only fine tune for 1 epoch - overfits fast\n",
        "student_model = train_tinybert(\n",
        "    student_model,\n",
        "    task_name,\n",
        "    train_dataloader,\n",
        "    eval_dataloader,\n",
        "    device,\n",
        "    output_mode,\n",
        "    num_labels,\n",
        "    eval_labels,\n",
        "    optimizer=None,\n",
        "    scheduler=None,\n",
        "    epochs=1\n",
        ")\n",
        "\n",
        "# SAVE MODEL\n",
        "model_path = '/content/tinyBert_sst2.pt'\n",
        "torch.save(student_model.state_dict(), model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfdOyWE-t8xq",
        "outputId": "4d7b1ca9-ce33-4de7-a6ea-131d2b4bddd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2105/2105 [02:35<00:00, 13.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.2796\n",
            "Training accuracy: 0.8867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 42.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.2928\n",
            "Validation accuracy: 0.8945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQz3yA4ujeOo"
      },
      "source": [
        "# Pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pruning Functions"
      ],
      "metadata": {
        "id": "4n1ji04DEv60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sparsity(tensor: torch.Tensor) -> float:\n",
        "    \"\"\"\n",
        "    calculate the sparsity of the given tensor\n",
        "        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n",
        "    \"\"\"\n",
        "    return 1 - float(tensor.count_nonzero()) / tensor.numel()\n",
        "\n",
        "\n",
        "def get_model_sparsity(model: nn.Module) -> float:\n",
        "    \"\"\"\n",
        "    calculate the sparsity of the given model\n",
        "        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n",
        "    \"\"\"\n",
        "    num_nonzeros, num_elements = 0, 0\n",
        "    for param in model.parameters():\n",
        "        num_nonzeros += param.count_nonzero()\n",
        "        num_elements += param.numel()\n",
        "    return 1 - float(num_nonzeros) / num_elements\n",
        "\n",
        "def get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n",
        "    \"\"\"\n",
        "    calculate the total number of parameters of model\n",
        "    :param count_nonzero_only: only count nonzero weights\n",
        "    \"\"\"\n",
        "    num_counted_elements = 0\n",
        "    for param in model.parameters():\n",
        "        if count_nonzero_only:\n",
        "            num_counted_elements += param.count_nonzero()\n",
        "        else:\n",
        "            num_counted_elements += param.numel()\n",
        "    return num_counted_elements\n",
        "\n",
        "\n",
        "def get_model_size(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n",
        "    \"\"\"\n",
        "    calculate the model size in bits\n",
        "    :param data_width: #bits per element\n",
        "    :param count_nonzero_only: only count nonzero weights\n",
        "    \"\"\"\n",
        "    return get_num_parameters(model, count_nonzero_only) * data_width"
      ],
      "metadata": {
        "id": "q0ce-FOuEz9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Structured Pruning"
      ],
      "metadata": {
        "id": "kA0NUi7Tlvgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def prune_embeddings(model: nn.Module, prune_ratios: Union[float, List[float]]) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Prune the embeddings layer of the model. This function prunes the word_embeddings, position_embeddings, token_type, and LayerNorm layers.\n",
        "\n",
        "    Args:\n",
        "        model: The language model to prune (e.g., TinyBERT).\n",
        "        prune_ratios: A single float or a list of floats specifying the prune ratio per layer.\n",
        "\n",
        "    Returns:\n",
        "        The pruned model.\n",
        "    \"\"\"\n",
        "\n",
        "    model = copy.deepcopy(model)  # Prevent overwriting the original model\n",
        "\n",
        "    # Get the original embedding matrix\n",
        "    word_embedding_layer = model.bert.embeddings.word_embeddings\n",
        "    position_embedding_layer = model.bert.embeddings.position_embeddings\n",
        "    token_type_embedding_layer = model.bert.embeddings.token_type_embeddings\n",
        "\n",
        "    original_word_embeddings = word_embedding_layer.weight.detach().cpu().numpy()\n",
        "    original_position_embeddings = position_embedding_layer.weight.detach().cpu().numpy()\n",
        "    original_token_type_embeddings = token_type_embedding_layer.weight.detach().cpu().numpy()\n",
        "\n",
        "    # Determine new embedding size (20% pruned)\n",
        "    original_word_dim = original_word_embeddings.shape[1]\n",
        "    original_position_dim = original_position_embeddings.shape[1]\n",
        "    original_token_type_dim = original_token_type_embeddings.shape[1]\n",
        "\n",
        "    new_word_dim = int(round(original_word_dim * prune_ratios))\n",
        "    new_position_dim = int(round(original_position_dim * prune_ratios))\n",
        "    new_token_type_dim = int(round(original_token_type_dim * prune_ratios))\n",
        "\n",
        "    # Perform PCA to reduce dimensionality\n",
        "    pca = PCA(n_components=new_word_dim)\n",
        "    reduced_embeddings = pca.fit_transform(original_word_embeddings)\n",
        "\n",
        "    pca = PCA(n_components=new_position_dim)\n",
        "    reduced_position_embeddings = pca.fit_transform(original_position_embeddings)\n",
        "\n",
        "    reduced_token_type_embeddings = original_token_type_embeddings[ : ,:new_token_type_dim ] # instead of using PCA for the token type layer, slice due to small size\n",
        "\n",
        "    ## word embeddings - replacing layer\n",
        "    # Convert reduced embeddings back to PyTorch format\n",
        "    new_word_embedding_layer = torch.nn.Embedding.from_pretrained(\n",
        "        torch.tensor(reduced_embeddings, dtype=torch.float32)\n",
        "    )\n",
        "    # Replace the embedding layer in the model\n",
        "    model.bert.embeddings.word_embeddings = new_word_embedding_layer\n",
        "\n",
        "\n",
        "    ## position embeddings - replacing layer\n",
        "    new_position_embedding_layer = torch.nn.Embedding.from_pretrained(\n",
        "        torch.tensor(reduced_position_embeddings, dtype=torch.float32)\n",
        "    )\n",
        "    model.bert.embeddings.position_embeddings = new_position_embedding_layer\n",
        "\n",
        "\n",
        "    ## token type embeddings - replacing layer\n",
        "    new_token_type_embedding_layer = torch.nn.Embedding.from_pretrained(\n",
        "        torch.tensor(reduced_token_type_embeddings, dtype=torch.float32)\n",
        "    )\n",
        "    model.bert.embeddings.token_type_embeddings = new_token_type_embedding_layer\n",
        "\n",
        "\n",
        "\n",
        "    ## pruning the layer norm (see the printed out layers a few cells below)\n",
        "    embedding_layernorm = model.bert.embeddings.LayerNorm\n",
        "    original_layernorm_dim = embedding_layernorm.weight.shape[0]\n",
        "    new_layernorm_dim = int(round(original_layernorm_dim * prune_ratios))\n",
        "\n",
        "    # Get indices to keep (assuming importance is based on weight magnitude)\n",
        "    importance = torch.abs(embedding_layernorm.weight)\n",
        "    _, idx_to_keep = torch.topk(importance, k=new_layernorm_dim)\n",
        "    idx_to_keep_sorted, _ = torch.sort(idx_to_keep)  # Ensure indices are sorted\n",
        "\n",
        "    # Prune the LayerNorm weight and bias\n",
        "    embedding_layernorm.weight = nn.Parameter(torch.index_select(embedding_layernorm.weight, 0, idx_to_keep_sorted))\n",
        "    embedding_layernorm.bias = nn.Parameter(torch.index_select(embedding_layernorm.bias, 0, idx_to_keep_sorted))\n",
        "\n",
        "    # Update LayerNorm's normalized_shape to match pruned dimension\n",
        "    embedding_layernorm.normalized_shape = (new_layernorm_dim,)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "jNoqstroxPQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate number of heads to keep\n",
        "def get_num_channels_to_keep(num_channels: int, prune_ratio: float) -> int:\n",
        "    return int(round(num_channels * (1 - prune_ratio)))\n",
        "\n",
        "@torch.no_grad()\n",
        "def prune_attention_channels(model: nn.Module, prune_ratios: Union[float, List[float]]) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Prune attention channels in the Transformer layers of the model.\n",
        "\n",
        "    Args:\n",
        "        model: The language model to prune (e.g., TinyBERT).\n",
        "        prune_ratios: A single float or a list of floats specifying the prune ratio per layer.\n",
        "\n",
        "    Returns:\n",
        "        The pruned model.\n",
        "    \"\"\"\n",
        "    model = copy.deepcopy(model)  # Prevent overwriting the original model\n",
        "\n",
        "    transformer_layers = model.bert.encoder.layer  # Assuming the model follows BERT's architecture\n",
        "    n_layers = len(transformer_layers)\n",
        "    print(\"Transformer Layers\")\n",
        "    print(transformer_layers)\n",
        "\n",
        "    # Ensure prune_ratios is a list\n",
        "    if isinstance(prune_ratios, float):\n",
        "        prune_ratios = [prune_ratios] * n_layers\n",
        "    else:\n",
        "        assert len(prune_ratios) == n_layers, \"Length of prune_ratios must match number of layers\"\n",
        "\n",
        "\n",
        "    # Prune channels by selecting the corresponding weights and biases\n",
        "    def prune_linear_layer(layer, idx_to_keep, dim=0):\n",
        "        new_weight = torch.index_select(layer.weight.data, 0, idx_to_keep)\n",
        "        new_weight = torch.index_select(new_weight, 1, idx_to_keep)\n",
        "        if layer.bias is not None:\n",
        "            # print(\"bias in prune_linear_layer: \", layer.bias.shape)\n",
        "            new_bias = torch.index_select(layer.bias.data, 0, idx_to_keep)\n",
        "\n",
        "        else:\n",
        "            new_bias = None\n",
        "        new_layer = nn.Linear(new_weight.size(1), new_weight.size(0), bias=layer.bias is not None)\n",
        "        new_layer.weight.data = new_weight.clone().detach()\n",
        "        if new_bias is not None:\n",
        "            new_layer.bias.data = new_bias.clone().detach()\n",
        "        return new_layer\n",
        "\n",
        "    def prune_LayerNorm(layer, idx_to_keep, dim=0):\n",
        "        # print(\"IDX linear: \", idx_to_keep)\n",
        "        # print(\"weight in prune_linear_layer: \", layer.weight.shape)\n",
        "\n",
        "        # Check if weight has more than one dimension before trying to select along dim 1\n",
        "        if layer.weight.dim() > 1:\n",
        "            new_weight = torch.index_select(layer.weight.data, 0, idx_to_keep)\n",
        "            new_weight = torch.index_select(new_weight, 1, idx_to_keep)\n",
        "        else:  # If it's 1-dimensional (like in LayerNorm), select only along dim 0\n",
        "            new_weight = torch.index_select(layer.weight.data, 0, idx_to_keep)\n",
        "\n",
        "        if layer.bias is not None:\n",
        "            # print(\"bias in prune_linear_layer: \", layer.bias.shape)\n",
        "            new_bias = torch.index_select(layer.bias.data, 0, idx_to_keep)\n",
        "        else:\n",
        "            new_bias = None\n",
        "\n",
        "        # Determine input and output features based on pruned weight dimensions\n",
        "        in_features = new_weight.size(1) if new_weight.dim() > 1 else new_weight.size(0) # Handle 1D case\n",
        "        out_features = new_weight.size(0)\n",
        "\n",
        "        new_layer = nn.Linear(in_features, out_features, bias=layer.bias is not None)\n",
        "        new_layer.weight.data = new_weight.clone().detach()\n",
        "        if new_bias is not None:\n",
        "            new_layer.bias.data = new_bias.clone().detach()\n",
        "        return new_layer\n",
        "\n",
        "    def prune_intermediate_layer(layer, idx_to_keep, dim=0):\n",
        "        new_weight = torch.index_select(layer.dense.weight.data, dim, idx_to_keep)\n",
        "\n",
        "        if layer.dense.bias is not None:\n",
        "            new_bias = torch.index_select(layer.dense.bias.data, 0, idx_to_keep)\n",
        "        else:\n",
        "            new_bias = None\n",
        "        # for output\n",
        "        new_layer = nn.Linear(new_weight.size(1), new_weight.size(0), bias=layer.dense.bias is not None)\n",
        "        new_layer.weight.data = new_weight.clone().detach()\n",
        "        if new_bias is not None:\n",
        "            new_layer.bias.data = new_bias.clone().detach()\n",
        "        return new_layer\n",
        "\n",
        "    def prune_out(layer, n_keep):\n",
        "      old_input_dim = layer.in_features\n",
        "      old_output_dim = layer.out_features\n",
        "      new_layer = nn.Linear(n_keep, old_output_dim)\n",
        "      with torch.no_grad():\n",
        "        if n_keep <= old_input_dim:\n",
        "          new_layer.weight[:, :n_keep] = layer.weight[:, :n_keep]\n",
        "          new_layer.bias = layer.bias\n",
        "        else:\n",
        "          print(\"New input dimension is larger than the old one. Reinitializing weights.\")\n",
        "      return new_layer\n",
        "\n",
        "\n",
        "    ## Prune Encoder Layers\n",
        "    for layer_idx, prune_ratio in enumerate(prune_ratios):\n",
        "        layer = transformer_layers[layer_idx]\n",
        "        attention = layer.attention.self\n",
        "        print(\"Layer\", layer_idx)\n",
        "\n",
        "        # Get the number of attention channels, number of heads, and head dimensions\n",
        "        num_channels = attention.query.weight.shape[0]\n",
        "        num_heads = attention.num_attention_heads\n",
        "        head_dim = attention.attention_head_size\n",
        "\n",
        "        # Get number of channels to keep after pruning\n",
        "        n_keep = get_num_channels_to_keep(num_channels, prune_ratio)\n",
        "        assert n_keep > 0, \"After pruning, at least one attention channel must remain\"\n",
        "\n",
        "        # Compute importance of each head (e.g., using the norm of the weights)\n",
        "        q_weight = attention.query.weight.view(num_channels, num_channels, -1)\n",
        "        k_weight = attention.key.weight.view(num_channels, num_channels, -1)\n",
        "        v_weight = attention.value.weight.view(num_channels, num_channels, -1)\n",
        "\n",
        "        # Sum norms across Q, K, V weights for each head\n",
        "        head_importance = (q_weight.norm(dim=(1, 2)) + k_weight.norm(dim=(1, 2)) + v_weight.norm(dim=(1, 2)))\n",
        "\n",
        "        # Get indices of heads to keep\n",
        "        _, idx = torch.sort(head_importance, descending=True)\n",
        "        idx_to_keep = idx[:n_keep]\n",
        "        idx_to_keep_sorted, _ = torch.sort(idx_to_keep)\n",
        "\n",
        "        # Prune Query, Key, Value linear layers\n",
        "        attention.query = prune_linear_layer(attention.query, idx_to_keep_sorted, dim=0)\n",
        "        attention.key = prune_linear_layer(attention.key, idx_to_keep_sorted, dim=0)\n",
        "        attention.value = prune_linear_layer(attention.value, idx_to_keep_sorted, dim=0)\n",
        "\n",
        "        # Prune Self-Output layer\n",
        "        layer.attention.output.dense = prune_linear_layer(layer.attention.output.dense, idx_to_keep_sorted, dim=1)\n",
        "\n",
        "        # Prune LayerNorm layer\n",
        "        layer.attention.output.LayerNorm = prune_LayerNorm(layer.attention.output.LayerNorm, idx_to_keep_sorted, dim=1)\n",
        "\n",
        "        # Prune Intermediate layer\n",
        "        layer.intermediate = prune_intermediate_layer(layer.intermediate, idx_to_keep_sorted, dim=1)\n",
        "\n",
        "        # Prune Output layer\n",
        "        layer.output = prune_intermediate_layer(layer.output, idx_to_keep_sorted, dim=0)\n",
        "\n",
        "        # Update attention_head_size\n",
        "        attention.attention_head_size = n_keep\n",
        "\n",
        "    ## Prune Pooler layer\n",
        "    model.bert.pooler.dense = prune_linear_layer(model.bert.pooler.dense, idx_to_keep_sorted, dim=1) # dim isn't used here actually\n",
        "\n",
        "    ## Prune Classifier layer\n",
        "    model.classifier = prune_out(model.classifier, n_keep)\n",
        "\n",
        "    ## Prune Fit Dense layer\n",
        "    model.fit_dense = prune_out(model.fit_dense, n_keep)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "V-fN2N-sFRxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prune ratios (e.g., pruning 20% of attention heads and FFN neurons)\n",
        "attention_prune_ratio = 0.2  # Prune 20% of attention heads\n",
        "ffn_prune_ratio = 0.2        # Prune 20% of FFN neurons\n",
        "\n",
        "# Prune attention heads\n",
        "pruned_model = prune_embeddings(student_model, 0.8)\n",
        "pruned_model = prune_attention_channels(pruned_model, attention_prune_ratio)\n",
        "\n",
        "# Prune FFN neurons\n",
        "# pruned_model = prune_ffn_neurons(pruned_model, ffn_prune_ratio)\n",
        "\n",
        "\n",
        "\n",
        "# pruned_model = monkey_patch_attention_output(pruned_model, device)\n",
        "pruned_model.to(device)\n",
        "# outputs = pruned_model(input_ids.to(device), attention_mask=attention_mask.to(device), token_type_ids=segment_ids.to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4zgqXTsb3_D",
        "outputId": "6dd5e7a8-9405-443c-821d-caac0116f1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer Layers\n",
            "ModuleList(\n",
            "  (0-3): 4 x BertLayer(\n",
            "    (attention): BertAttention(\n",
            "      (self): BertSelfAttention(\n",
            "        (query): Linear(in_features=312, out_features=312, bias=True)\n",
            "        (key): Linear(in_features=312, out_features=312, bias=True)\n",
            "        (value): Linear(in_features=312, out_features=312, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (output): BertSelfOutput(\n",
            "        (dense): Linear(in_features=312, out_features=312, bias=True)\n",
            "        (LayerNorm): BertLayerNorm()\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (intermediate): BertIntermediate(\n",
            "      (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
            "    )\n",
            "    (output): BertOutput(\n",
            "      (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
            "      (LayerNorm): BertLayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Layer 0\n",
            "Layer 1\n",
            "Layer 2\n",
            "Layer 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyBertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 250)\n",
              "      (position_embeddings): Embedding(512, 250)\n",
              "      (token_type_embeddings): Embedding(2, 250)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-3): 4 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=250, out_features=250, bias=True)\n",
              "              (key): Linear(in_features=250, out_features=250, bias=True)\n",
              "              (value): Linear(in_features=250, out_features=250, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=250, out_features=250, bias=True)\n",
              "              (LayerNorm): Linear(in_features=250, out_features=250, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Linear(in_features=250, out_features=1200, bias=True)\n",
              "          (output): Linear(in_features=1200, out_features=250, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=250, out_features=250, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=250, out_features=2, bias=True)\n",
              "  (fit_dense): Linear(in_features=250, out_features=768, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model"
      ],
      "metadata": {
        "id": "OeG5gnFOhpmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc66319d-dbf5-4ca5-a91f-28d351f75e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyBertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 250)\n",
              "      (position_embeddings): Embedding(512, 250)\n",
              "      (token_type_embeddings): Embedding(2, 250)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-3): 4 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=250, out_features=250, bias=True)\n",
              "              (key): Linear(in_features=250, out_features=250, bias=True)\n",
              "              (value): Linear(in_features=250, out_features=250, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=250, out_features=250, bias=True)\n",
              "              (LayerNorm): Linear(in_features=250, out_features=250, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=250, out_features=1200, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=1200, out_features=250, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=250, out_features=250, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=250, out_features=2, bias=True)\n",
              "  (fit_dense): Linear(in_features=250, out_features=768, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in pruned_model.named_parameters():\n",
        "    print(f\"{name}: {param.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yezi27whnsj",
        "outputId": "5b4d723f-f643-49b4-c5d7-49a606252827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight: torch.Size([30522, 250])\n",
            "bert.embeddings.position_embeddings.weight: torch.Size([512, 250])\n",
            "bert.embeddings.token_type_embeddings.weight: torch.Size([2, 250])\n",
            "bert.embeddings.LayerNorm.weight: torch.Size([250])\n",
            "bert.embeddings.LayerNorm.bias: torch.Size([250])\n",
            "bert.encoder.layer.0.attention.self.query.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.0.attention.self.query.bias: torch.Size([250])\n",
            "bert.encoder.layer.0.attention.self.key.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.0.attention.self.key.bias: torch.Size([250])\n",
            "bert.encoder.layer.0.attention.self.value.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.0.attention.self.value.bias: torch.Size([250])\n",
            "bert.encoder.layer.0.attention.output.dense.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.0.attention.output.dense.bias: torch.Size([250])\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight: torch.Size([250])\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias: torch.Size([250])\n",
            "bert.encoder.layer.0.intermediate.weight: torch.Size([1200, 250])\n",
            "bert.encoder.layer.0.intermediate.bias: torch.Size([250])\n",
            "bert.encoder.layer.0.output.weight: torch.Size([250, 1200])\n",
            "bert.encoder.layer.0.output.bias: torch.Size([250])\n",
            "bert.encoder.layer.1.attention.self.query.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.1.attention.self.query.bias: torch.Size([250])\n",
            "bert.encoder.layer.1.attention.self.key.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.1.attention.self.key.bias: torch.Size([250])\n",
            "bert.encoder.layer.1.attention.self.value.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.1.attention.self.value.bias: torch.Size([250])\n",
            "bert.encoder.layer.1.attention.output.dense.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.1.attention.output.dense.bias: torch.Size([250])\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight: torch.Size([250])\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias: torch.Size([250])\n",
            "bert.encoder.layer.1.intermediate.weight: torch.Size([1200, 250])\n",
            "bert.encoder.layer.1.intermediate.bias: torch.Size([250])\n",
            "bert.encoder.layer.1.output.weight: torch.Size([250, 1200])\n",
            "bert.encoder.layer.1.output.bias: torch.Size([250])\n",
            "bert.encoder.layer.2.attention.self.query.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.2.attention.self.query.bias: torch.Size([250])\n",
            "bert.encoder.layer.2.attention.self.key.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.2.attention.self.key.bias: torch.Size([250])\n",
            "bert.encoder.layer.2.attention.self.value.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.2.attention.self.value.bias: torch.Size([250])\n",
            "bert.encoder.layer.2.attention.output.dense.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.2.attention.output.dense.bias: torch.Size([250])\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight: torch.Size([250])\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias: torch.Size([250])\n",
            "bert.encoder.layer.2.intermediate.weight: torch.Size([1200, 250])\n",
            "bert.encoder.layer.2.intermediate.bias: torch.Size([250])\n",
            "bert.encoder.layer.2.output.weight: torch.Size([250, 1200])\n",
            "bert.encoder.layer.2.output.bias: torch.Size([250])\n",
            "bert.encoder.layer.3.attention.self.query.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.3.attention.self.query.bias: torch.Size([250])\n",
            "bert.encoder.layer.3.attention.self.key.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.3.attention.self.key.bias: torch.Size([250])\n",
            "bert.encoder.layer.3.attention.self.value.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.3.attention.self.value.bias: torch.Size([250])\n",
            "bert.encoder.layer.3.attention.output.dense.weight: torch.Size([250, 250])\n",
            "bert.encoder.layer.3.attention.output.dense.bias: torch.Size([250])\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight: torch.Size([250])\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias: torch.Size([250])\n",
            "bert.encoder.layer.3.intermediate.weight: torch.Size([1200, 250])\n",
            "bert.encoder.layer.3.intermediate.bias: torch.Size([250])\n",
            "bert.encoder.layer.3.output.weight: torch.Size([250, 1200])\n",
            "bert.encoder.layer.3.output.bias: torch.Size([250])\n",
            "bert.pooler.dense.weight: torch.Size([250, 250])\n",
            "bert.pooler.dense.bias: torch.Size([250])\n",
            "classifier.weight: torch.Size([2, 250])\n",
            "classifier.bias: torch.Size([2])\n",
            "fit_dense.weight: torch.Size([768, 250])\n",
            "fit_dense.bias: torch.Size([768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(pruned_model, eval_dataloader, device)"
      ],
      "metadata": {
        "id": "4kTTmeXMPZ4O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "a79710b2-2de7-4f74-b978-3630e2740260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 128])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[32, 128, 12, 250]' is invalid for input of size 1024000",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-e35017be6bed>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpruned_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-d5a324fb8c08>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get predicted labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Pretrained-Language-Model/TinyBERT/transformer/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, labels, is_student)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 labels=None, is_student=False):\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         sequence_output, att_output, pooled_output = self.bert(input_ids, token_type_ids, attention_mask,\n\u001b[0m\u001b[1;32m   1133\u001b[0m                                                                output_all_encoded_layers=True, output_att=True)\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Pretrained-Language-Model/TinyBERT/transformer/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers, output_att)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         encoded_layers, layer_atts = self.encoder(embedding_output,\n\u001b[0m\u001b[1;32m    834\u001b[0m                                                   extended_attention_mask)\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Pretrained-Language-Model/TinyBERT/transformer/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             hidden_states, layer_att = layer_module(\n\u001b[0m\u001b[1;32m    515\u001b[0m                 hidden_states, attention_mask)\n\u001b[1;32m    516\u001b[0m             \u001b[0mall_encoder_atts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_att\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Pretrained-Language-Model/TinyBERT/transformer/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         attention_output, layer_att = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             hidden_states, attention_mask)\n\u001b[1;32m    497\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Pretrained-Language-Model/TinyBERT/transformer/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_att\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Pretrained-Language-Model/TinyBERT/transformer/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_att)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mmixed_value_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_key_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_value_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Pretrained-Language-Model/TinyBERT/transformer/modeling.py\u001b[0m in \u001b[0;36mtranspose_for_scores\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    386\u001b[0m         new_x_shape = x.size()[\n\u001b[1;32m    387\u001b[0m             :-1] + (self.num_attention_heads, self.attention_head_size)\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_x_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[32, 128, 12, 250]' is invalid for input of size 1024000"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix: Old Attempts"
      ],
      "metadata": {
        "id": "gY_l_NLubd6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def monkey_patch_attention_output(model):\n",
        "    for i, layer in enumerate(model.bert.encoder.layer):\n",
        "        pruned_hidden_size = layer.attention.self.num_attention_heads * layer.attention.self.attention_head_size\n",
        "        original_hidden_size = layer.attention.output.dense.out_features\n",
        "\n",
        "        if pruned_hidden_size != original_hidden_size:\n",
        "            print(f\"Monkey-patching layer {i}: {pruned_hidden_size} -> {original_hidden_size}\")\n",
        "            # layer.attention.output.proj_back_to_hidden = nn.Linear(pruned_hidden_size, original_hidden_size, bias=False)\n",
        "            layer.attention.output.proj_back_to_hidden = nn.Linear(pruned_hidden_size, original_hidden_size, bias=False).to(device)\n",
        "\n",
        "            def new_forward(self, hidden_states, input_tensor):\n",
        "              print(\"Inside patched forward - Before dense:\", hidden_states.shape)\n",
        "              # If the hidden_states are pruned and you have proj_back_to_hidden,\n",
        "              # apply it BEFORE the dense layer\n",
        "              if hasattr(self, 'proj_back_to_hidden'):\n",
        "                  hidden_states = self.proj_back_to_hidden(hidden_states)\n",
        "                  print(\"Inside patched forward - After proj_back_to_hidden:\", hidden_states.shape)\n",
        "\n",
        "              hidden_states = self.dense(hidden_states)  # now hidden_states has the expected dimension\n",
        "              print(\"Inside patched forward - After dense:\", hidden_states.shape)\n",
        "              hidden_states = self.dropout(hidden_states)\n",
        "              hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "              print(\"Inside patched forward - After LayerNorm:\", hidden_states.shape)\n",
        "              return hidden_states\n",
        "\n",
        "\n",
        "            layer.attention.output.forward = new_forward.__get__(layer.attention.output, type(layer.attention.output))\n",
        "    return model\n",
        "\n",
        "pruned_model = monkey_patch_attention_output(pruned_model)\n",
        "pruned_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "u-DwGS5R0Cpp",
        "outputId": "1f0c485a-9aff-4f0d-8f04-4844aca0fe8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pruned_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bb85d20b765f>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mpruned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonkey_patch_attention_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpruned_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mpruned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pruned_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "def monkey_patch_attention_output(model, device):\n",
        "    for i, layer in enumerate(model.bert.encoder.layer):\n",
        "        pruned_hidden_size = layer.attention.self.num_attention_heads * layer.attention.self.attention_head_size\n",
        "        original_hidden_size = layer.attention.output.dense.out_features\n",
        "\n",
        "        if pruned_hidden_size != original_hidden_size:\n",
        "            print(f\"Monkey-patching layer {i}: {pruned_hidden_size} -> {original_hidden_size}\")\n",
        "            # Create projection on CPU by default, then move to device\n",
        "            layer.attention.output.proj_back_to_hidden = nn.Linear(pruned_hidden_size, original_hidden_size, bias=False)\n",
        "            layer.attention.output.proj_back_to_hidden.to(device)  # Move this new layer to GPU\n",
        "\n",
        "            def new_forward(self, hidden_states, input_tensor):\n",
        "                # If pruning changed the dimensions, we must project before dense\n",
        "                if hasattr(self, 'proj_back_to_hidden'):\n",
        "                    hidden_states = self.proj_back_to_hidden(hidden_states)  # This will now be on GPU\n",
        "                hidden_states = self.dense(hidden_states)\n",
        "                hidden_states = self.dropout(hidden_states)\n",
        "                hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "                return hidden_states\n",
        "\n",
        "            # Monkey-patch the forward method\n",
        "            layer.attention.output.forward = new_forward.__get__(layer.attention.output, type(layer.attention.output))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define prune ratios (e.g., pruning 20% of attention heads and FFN neurons)\n",
        "attention_prune_ratio = 0.2  # Prune 20% of attention heads\n",
        "ffn_prune_ratio = 0.2        # Prune 20% of FFN neurons\n",
        "\n",
        "# Prune attention heads\n",
        "pruned_model = prune_attention_heads(student_model, attention_prune_ratio)\n",
        "\n",
        "# Prune FFN neurons\n",
        "# pruned_model = prune_ffn_neurons(pruned_model, ffn_prune_ratio)\n",
        "\n",
        "\n",
        "# pruned_model = monkey_patch_attention_output(pruned_model, device)\n",
        "pruned_model.to(device)\n",
        "\n",
        "# outputs = pruned_model(input_ids.to(device), attention_mask=attention_mask.to(device), token_type_ids=segment_ids.to(device))\n"
      ],
      "metadata": {
        "id": "l5Eyb4ulPUtM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b385acf6-5b27-49b0-bc9c-8136a8cd66d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer Layers\n",
            "ModuleList(\n",
            "  (0-3): 4 x BertLayer(\n",
            "    (attention): BertAttention(\n",
            "      (self): BertSelfAttention(\n",
            "        (query): Linear(in_features=312, out_features=312, bias=True)\n",
            "        (key): Linear(in_features=312, out_features=312, bias=True)\n",
            "        (value): Linear(in_features=312, out_features=312, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (output): BertSelfOutput(\n",
            "        (dense): Linear(in_features=312, out_features=312, bias=True)\n",
            "        (LayerNorm): BertLayerNorm()\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (intermediate): BertIntermediate(\n",
            "      (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
            "    )\n",
            "    (output): BertOutput(\n",
            "      (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
            "      (LayerNorm): BertLayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Layer 0\n",
            "Attention BertSelfAttention(\n",
            "  (query): Linear(in_features=312, out_features=312, bias=True)\n",
            "  (key): Linear(in_features=312, out_features=312, bias=True)\n",
            "  (value): Linear(in_features=312, out_features=312, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "BertIntermediate(\n",
            "  (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
            ")\n",
            "BertOutput(\n",
            "  (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
            "  (LayerNorm): BertLayerNorm()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Layer 1\n",
            "Attention BertSelfAttention(\n",
            "  (query): Linear(in_features=312, out_features=312, bias=True)\n",
            "  (key): Linear(in_features=312, out_features=312, bias=True)\n",
            "  (value): Linear(in_features=312, out_features=312, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "BertIntermediate(\n",
            "  (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
            ")\n",
            "BertOutput(\n",
            "  (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
            "  (LayerNorm): BertLayerNorm()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Layer 2\n",
            "Attention BertSelfAttention(\n",
            "  (query): Linear(in_features=312, out_features=312, bias=True)\n",
            "  (key): Linear(in_features=312, out_features=312, bias=True)\n",
            "  (value): Linear(in_features=312, out_features=312, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "BertIntermediate(\n",
            "  (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
            ")\n",
            "BertOutput(\n",
            "  (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
            "  (LayerNorm): BertLayerNorm()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "Layer 3\n",
            "Attention BertSelfAttention(\n",
            "  (query): Linear(in_features=312, out_features=312, bias=True)\n",
            "  (key): Linear(in_features=312, out_features=312, bias=True)\n",
            "  (value): Linear(in_features=312, out_features=312, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "BertIntermediate(\n",
            "  (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
            ")\n",
            "BertOutput(\n",
            "  (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
            "  (LayerNorm): BertLayerNorm()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyBertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 312)\n",
              "      (token_type_embeddings): Embedding(2, 312)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-3): 4 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=260, out_features=260, bias=True)\n",
              "              (key): Linear(in_features=260, out_features=260, bias=True)\n",
              "              (value): Linear(in_features=260, out_features=260, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=260, out_features=312, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Linear(in_features=10, out_features=1200, bias=True)\n",
              "          (output): Linear(in_features=1200, out_features=10, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=312, out_features=2, bias=True)\n",
              "  (fit_dense): Linear(in_features=312, out_features=768, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix20dAV1Zxr_",
        "outputId": "c5b2e21d-7e7e-4354-cd3a-b64c27dba81e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyBertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 312)\n",
              "      (token_type_embeddings): Embedding(2, 312)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-3): 4 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=260, out_features=260, bias=True)\n",
              "              (key): Linear(in_features=260, out_features=260, bias=True)\n",
              "              (value): Linear(in_features=260, out_features=260, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=260, out_features=312, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Linear(in_features=10, out_features=1200, bias=True)\n",
              "          (output): Linear(in_features=1200, out_features=10, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=312, out_features=2, bias=True)\n",
              "  (fit_dense): Linear(in_features=312, out_features=768, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def monkey_patch_ffn_output(model):\n",
        "    for i, layer in enumerate(model.bert.encoder.layer):\n",
        "        # After pruning FFN, input to BertOutput might be reduced\n",
        "        pruned_hidden_size = layer.intermediate.dense.out_features\n",
        "        original_hidden_size = layer.output.dense.in_features\n",
        "\n",
        "        if pruned_hidden_size != original_hidden_size:\n",
        "            layer.output.proj_back_to_hidden = nn.Linear(pruned_hidden_size, original_hidden_size, bias=False)\n",
        "\n",
        "            def new_output_forward(self, hidden_states, input_tensor):\n",
        "                hidden_states = self.dense(hidden_states)\n",
        "                # Apply projection if present\n",
        "                if hasattr(self, 'proj_back_to_hidden'):\n",
        "                    hidden_states = self.proj_back_to_hidden(hidden_states)\n",
        "                hidden_states = self.dropout(hidden_states)\n",
        "                hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "                return hidden_states\n",
        "\n",
        "            layer.output.forward = new_output_forward.__get__(layer.output, type(layer.output))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "5yhncslH4xcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def prune_ffn_neurons(model: nn.Module, prune_ratios: Union[float, List[float]]) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Prune neurons in the feed-forward networks of the Transformer layers.\n",
        "\n",
        "    Args:\n",
        "        model: The language model to prune.\n",
        "        prune_ratios: A single float or a list of floats specifying the prune ratio per layer.\n",
        "\n",
        "    Returns:\n",
        "        The pruned model.\n",
        "    \"\"\"\n",
        "    model = copy.deepcopy(model)\n",
        "    transformer_layers = model.bert.encoder.layer\n",
        "    n_layers = len(transformer_layers)\n",
        "\n",
        "    # Ensure prune_ratios is a list\n",
        "    if isinstance(prune_ratios, float):\n",
        "        prune_ratios = [prune_ratios] * n_layers\n",
        "    else:\n",
        "        assert len(prune_ratios) == n_layers, \"Length of prune_ratios must match number of layers\"\n",
        "\n",
        "    for layer_idx, prune_ratio in enumerate(prune_ratios):\n",
        "        layer = transformer_layers[layer_idx]\n",
        "        ffn = layer.intermediate\n",
        "        output_ffn = layer.output\n",
        "\n",
        "        # Get the number of neurons in the intermediate dense layer\n",
        "        hidden_dim = ffn.dense.weight.size(0)\n",
        "\n",
        "        # Calculate number of neurons to keep\n",
        "        n_keep = get_num_units_to_keep(hidden_dim, prune_ratio)\n",
        "        assert n_keep > 0, \"After pruning, at least one neuron must remain in FFN\"\n",
        "\n",
        "        # Compute importance of each neuron (e.g., using the norm of the weights)\n",
        "        neuron_importance = ffn.dense.weight.norm(dim=1)\n",
        "\n",
        "        # Get indices of neurons to keep\n",
        "        _, idx = torch.sort(neuron_importance, descending=True)\n",
        "        idx_to_keep = idx[:n_keep]\n",
        "        idx_to_keep_sorted, _ = torch.sort(idx_to_keep)\n",
        "\n",
        "        # Prune the intermediate dense layer\n",
        "        new_ffn_dense = nn.Linear(ffn.dense.in_features, n_keep)\n",
        "        new_ffn_dense.weight.data = torch.index_select(ffn.dense.weight.data, 0, idx_to_keep_sorted).clone().detach()\n",
        "        new_ffn_dense.bias.data = torch.index_select(ffn.dense.bias.data, 0, idx_to_keep_sorted).clone().detach()\n",
        "        ffn.dense = new_ffn_dense\n",
        "\n",
        "        # Prune the output dense layer\n",
        "        new_output_dense = nn.Linear(n_keep, output_ffn.dense.out_features)\n",
        "        new_output_dense.weight.data = torch.index_select(output_ffn.dense.weight.data, 1, idx_to_keep_sorted).clone().detach()\n",
        "        new_output_dense.bias.data = output_ffn.dense.bias.data.clone().detach()\n",
        "        output_ffn.dense = new_output_dense\n",
        "\n",
        "        # Add a projection layer for the residual connection\n",
        "        if n_keep != output_ffn.dense.out_features:\n",
        "            output_ffn.residual_proj = nn.Linear(n_keep, output_ffn.dense.out_features, bias=False)\n",
        "        else:\n",
        "            output_ffn.residual_proj = nn.Identity()  # If dimensions match, use an identity layer\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "O_If-7N0Uck5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" * Without sorting...\")\n",
        "pruned_model_accuracy = evaluate(pruned_model)\n",
        "unpruned_model_accuracy = evaluate(student_model)\n",
        "print(f\"Unpruned model has accuracy={unpruned_model_accuracy['acc']*100:.2f}%\")\n",
        "print(f\"pruned model has accuracy={pruned_model_accuracy['acc']*100:.2f}%\")\n",
        "pruned_model_size = get_model_size(pruned_model)\n",
        "student_model_size = get_model_size(student_model)\n",
        "print(f\"Unpruned model has size={student_model_size/MiB:.2f} MiB\")\n",
        "print(f\"Pruned model has size={pruned_model_size/MiB:.2f} MiB\")\n",
        "\n",
        "# only finetune for 1 epoch - overfits fast\n",
        "fine_tuned_pruned_model = train_tinybert(\n",
        "    pruned_model,\n",
        "    task_name,\n",
        "    train_dataloader,\n",
        "    eval_dataloader,\n",
        "    device,\n",
        "    output_mode,\n",
        "    num_labels,\n",
        "    eval_labels,\n",
        "    optimizer=None,\n",
        "    scheduler=None,\n",
        "    epochs=1\n",
        ")\n",
        "\n",
        "# print(\" * With sorting...\")\n",
        "# sorted_model = apply_channel_sorting(student_model)\n",
        "# pruned_model = channel_prune(sorted_model, channel_pruning_ratio)\n",
        "# pruned_model_accuracy = evaluate(pruned_model)\n",
        "# print(f\"pruned model has accuracy={pruned_model_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "viMGpfhpPeDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4n1ji04DEv60",
        "2fpXS_vKJ9bj",
        "dxrl5D-RQWkK",
        "nIdbquLnjagP"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}