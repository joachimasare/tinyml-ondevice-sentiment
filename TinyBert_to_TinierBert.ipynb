{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Hnfpatg-R95u",
        "bytVEtQ1Ugox"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhfGiC14OmnD"
      },
      "outputs": [],
      "source": [
        "# imports needed for pytorch tinyBERT project\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "import csv\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import copy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset and Model"
      ],
      "metadata": {
        "id": "mi46HU5zO2gY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TinyBert github: https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT"
      ],
      "metadata": {
        "id": "ngMmLNqvO4z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading dataset\n",
        "!git clone https://github.com/nyu-mll/GLUE-baselines.git\n",
        "!python GLUE-baselines/download_glue_data.py --data_dir /content --tasks SST"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skXl_fiYOuWc",
        "outputId": "b828ae74-c339-4684-cefb-854fa65c17cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GLUE-baselines'...\n",
            "remote: Enumerating objects: 891, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 891 (delta 1), reused 3 (delta 1), pack-reused 886 (from 1)\u001b[K\n",
            "Receiving objects: 100% (891/891), 1.48 MiB | 24.40 MiB/s, done.\n",
            "Resolving deltas: 100% (610/610), done.\n",
            "Downloading and extracting SST...\n",
            "\tCompleted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download tinyBERT source code and install dependencies\n",
        "!git clone https://github.com/huawei-noah/Pretrained-Language-Model.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUkPhgx0Oxxl",
        "outputId": "db490ee5-a641-4865-ad9c-b56dbe153c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Pretrained-Language-Model'...\n",
            "remote: Enumerating objects: 1253, done.\u001b[K\n",
            "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 1253 (delta 173), reused 120 (delta 119), pack-reused 973 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1253/1253), 29.72 MiB | 16.50 MiB/s, done.\n",
            "Resolving deltas: 100% (540/540), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Pretrained-Language-Model/TinyBERT\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "435fVaBoOyUu",
        "outputId": "76da6c61-3e4d-47fd-f56e-ba427256a72e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Pretrained-Language-Model/TinyBERT\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.66.6)\n",
            "Collecting boto3 (from -r requirements.txt (line 4))\n",
            "  Downloading boto3-1.35.81-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.5.1+cu121)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.13.2)\n",
            "Collecting botocore<1.36.0,>=1.35.81 (from boto3->-r requirements.txt (line 4))\n",
            "  Downloading botocore-1.35.81-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->-r requirements.txt (line 4))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->-r requirements.txt (line 4))\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->-r requirements.txt (line 8)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->-r requirements.txt (line 8)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->-r requirements.txt (line 8)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->-r requirements.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->-r requirements.txt (line 8)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->-r requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.1->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy>=0.14.0->-r requirements.txt (line 9)) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn->-r requirements.txt (line 10)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn->-r requirements.txt (line 10)) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.81->boto3->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 10)) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 10)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 10)) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.1->-r requirements.txt (line 8)) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.81->boto3->-r requirements.txt (line 4)) (1.17.0)\n",
            "Downloading boto3-1.35.81-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.81-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.35.81 botocore-1.35.81 jmespath-1.0.1 s3transfer-0.10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Dependencies"
      ],
      "metadata": {
        "id": "w9Y2oFrrO9C-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLhyyIM4O0Au",
        "outputId": "4045ad68-db2b-4688-cb59-3ba4286f778f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7caf580ad070>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Installing torchprofile...')\n",
        "!pip install torchprofile 1>/dev/null\n",
        "print('Installing fast-pytorch-kmeans...')\n",
        "! pip install fast-pytorch-kmeans 1>/dev/null\n",
        "print('All required packages have been successfully installed!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PSBOYtLO_-P",
        "outputId": "2cd21c48-925f-45a6-f641-f1c8f642a75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing torchprofile...\n",
            "Installing fast-pytorch-kmeans...\n",
            "All required packages have been successfully installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchprofile import profile_macs\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "EX4g8uoMSTHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading BERT-base code: https://github.com/google-research/bert?tab=readme-ov-file\n",
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
        "!unzip cased_L-12_H-768_A-12.zip\n",
        "!cp cased_L-12_H-768_A-12/bert_config.json cased_L-12_H-768_A-12/config.json # must rename bert_config to config\n",
        "\n",
        "BERT_BASE_DIR = 'cased_L-12_H-768_A-12'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4EVYhxpPB-I",
        "outputId": "2bf7a9eb-9a37-433a-beb8-69a72efea084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-14 17:49:10--  https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.200.207, 74.125.130.207, 74.125.68.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.200.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 404261442 (386M) [application/zip]\n",
            "Saving to: ‘cased_L-12_H-768_A-12.zip’\n",
            "\n",
            "cased_L-12_H-768_A- 100%[===================>] 385.53M  18.2MB/s    in 20s     \n",
            "\n",
            "2024-12-14 17:49:32 (18.9 MB/s) - ‘cased_L-12_H-768_A-12.zip’ saved [404261442/404261442]\n",
            "\n",
            "Archive:  cased_L-12_H-768_A-12.zip\n",
            "   creating: cased_L-12_H-768_A-12/\n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: cased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_config.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cloning TinyBert pretrained models\n",
        "!git clone https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D\n",
        "\n",
        "STUDENT_CONFIG_DIR = '/content/Pretrained-Language-Model/TinyBERT/TinyBERT_General_4L_312D'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho5G37N9PGaW",
        "outputId": "63b9b4d2-bbe7-41bf-a116-0649b268487e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TinyBERT_General_4L_312D'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Total 24 (delta 0), reused 0 (delta 0), pack-reused 24 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (24/24), 111.20 KiB | 8.55 MiB/s, done.\n",
            "Filtering content: 100% (2/2), 114.58 MiB | 30.03 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_size(model: nn.Module, data_width=32):\n",
        "    \"\"\"\n",
        "    calculate the model size in bits\n",
        "    :param data_width: #bits per element\n",
        "    \"\"\"\n",
        "    num_elements = 0\n",
        "    for param in model.parameters():\n",
        "        num_elements += param.numel()\n",
        "    return num_elements * data_width\n",
        "\n",
        "Byte = 8\n",
        "KiB = 1024 * Byte\n",
        "MiB = 1024 * KiB\n",
        "GiB = 1024 * MiB"
      ],
      "metadata": {
        "id": "9tCSVJIsPNrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How large is TinyBert to begin with?"
      ],
      "metadata": {
        "id": "2Fncgni_Pe6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformer.modeling import TinyBertForPreTraining, BertModel, TinyBertForSequenceClassification"
      ],
      "metadata": {
        "id": "b-hJl0UAPVBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STUDENT_CONFIG_DIR = '/content/Pretrained-Language-Model/TinyBERT/TinyBERT_General_4L_312D'\n",
        "BERT_BASE_DIR = '/content/Pretrained-Language-Model/TinyBERT/cased_L-12_H-768_A-12'"
      ],
      "metadata": {
        "id": "kQZyeYI3PlH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 2\n",
        "student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)\n",
        "teacher_model = BertModel.from_scratch(BERT_BASE_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgU6-4lBPqwC",
        "outputId": "6554227f-6ac2-4803-b8f1-fe0862b5dd5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Pretrained-Language-Model/TinyBERT/transformer/modeling.py:696: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(weights_path, map_location='cpu')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STORAGE\n",
        "student_model_size = get_model_size(student_model)\n",
        "teacher_model_size = get_model_size(teacher_model)\n",
        "\n",
        "print(\"Student model size: \", student_model_size/MiB, \"MiB\")\n",
        "print(\"Teacher model size: \", teacher_model_size/MiB, \"MiB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYdBIuhPPvGO",
        "outputId": "3dcb31ab-99a4-4d0a-8e55-76ffead6d230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student model size:  55.661231994628906 MiB\n",
            "Teacher model size:  413.1708984375 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating TinyBert"
      ],
      "metadata": {
        "id": "GZbC8gpPP1BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from task_distill import convert_examples_to_features, get_tensor_data, InputExample, InputFeatures, DataProcessor, Sst2Processor\n",
        "from torch.utils.data import SequentialSampler\n",
        "from transformer.modeling import TinyBertForPreTraining, BertModel, TinyBertForSequenceClassification"
      ],
      "metadata": {
        "id": "_RvqjymXQH5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_accuracy(preds, labels):\n",
        "    return (preds == labels).mean()\n",
        "\n",
        "def compute_metrics(task_name, preds, labels):\n",
        "    assert len(preds) == len(labels)\n",
        "    return {\"acc\": simple_accuracy(preds, labels)}\n",
        "\n",
        "# evaluation function based on  task_distill.py --do_eval\n",
        "def evaluate_tinybert(model, task_name, eval_dataloader,\n",
        "            device, output_mode, eval_labels, num_labels):\n",
        "    eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    preds = []\n",
        "\n",
        "    model.eval()\n",
        "    for batch_ in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        batch_ = tuple(t.to(device) for t in batch_)\n",
        "        with torch.no_grad():\n",
        "            input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch_\n",
        "\n",
        "            # ValueError: not enough values to unpack (expected 3, got 2)\n",
        "            # logits, _, _ = model(input_ids, segment_ids, input_mask)\n",
        "            # TODO: what is the model outputting? What\n",
        "            logits, _ , _= model(input_ids, segment_ids, input_mask)\n",
        "\n",
        "\n",
        "        # create eval loss and other metric required by the task\n",
        "        if output_mode == \"classification\":\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            tmp_eval_loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
        "        elif output_mode == \"regression\":\n",
        "            loss_fct = MSELoss()\n",
        "            tmp_eval_loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "\n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "        if len(preds) == 0:\n",
        "            preds.append(logits.detach().cpu().numpy())\n",
        "        else:\n",
        "            preds[0] = np.append(\n",
        "                preds[0], logits.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "\n",
        "    preds = preds[0]\n",
        "    if output_mode == \"classification\":\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "    elif output_mode == \"regression\":\n",
        "        preds = np.squeeze(preds)\n",
        "    result = compute_metrics(task_name, preds, eval_labels.numpy())\n",
        "    result['eval_loss'] = eval_loss\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "output_mode = \"classification\"\n"
      ],
      "metadata": {
        "id": "2dI-1E6GQIz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the evaluation dataloader\n",
        "do_lower_case = False\n",
        "data_dir = '/content/SST-2'\n",
        "processor = Sst2Processor()\n",
        "label_list = processor.get_labels()\n",
        "num_labels = len(label_list)\n",
        "max_seq_length = 128\n",
        "eval_batch_size = 32\n",
        "task_name = \"sst2\"\n",
        "output_mode = \"classification\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)\n",
        "student_model.to(device)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(STUDENT_CONFIG_DIR, do_lower_case=do_lower_case)\n",
        "eval_examples = processor.get_dev_examples(data_dir)\n",
        "eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "eval_data, eval_labels = get_tensor_data(output_mode, eval_features)\n",
        "eval_sampler = SequentialSampler(eval_data)\n",
        "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
        "\n",
        "# check that the evaluate_tinybert function is working\n",
        "evaluate_tinybert(student_model, task_name, eval_dataloader,\n",
        "            device, output_mode, eval_labels, num_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe7Sb561RA2z",
        "outputId": "474caa03-adfe-4589-ed70-ccc43f9693b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:01<00:00, 14.26it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': 0.47706422018348627, 'eval_loss': 0.6937263650553567}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# method that both sets up the dataset and runs evaluation on TinyBert\n",
        "def evaluate(student_model):\n",
        "  # building the evaluation dataloader\n",
        "  do_lower_case = False\n",
        "  data_dir = '/content/SST-2'\n",
        "  processor = Sst2Processor()\n",
        "  label_list = processor.get_labels()\n",
        "  num_labels = len(label_list)\n",
        "  max_seq_length = 128\n",
        "  eval_batch_size = 32\n",
        "  task_name = \"sst2\"\n",
        "  output_mode = \"classification\"\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  student_model.to(device)\n",
        "\n",
        "  #TODO: does this tokenizer still work?\n",
        "  tokenizer = BertTokenizer.from_pretrained(STUDENT_CONFIG_DIR, do_lower_case=do_lower_case)\n",
        "  eval_examples = processor.get_dev_examples(data_dir)\n",
        "  eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "  eval_data, eval_labels = get_tensor_data(output_mode, eval_features)\n",
        "  eval_sampler = SequentialSampler(eval_data)\n",
        "  eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
        "\n",
        "  res = evaluate_tinybert(student_model, task_name, eval_dataloader,\n",
        "              device, output_mode, eval_labels, num_labels)\n",
        "  return res"
      ],
      "metadata": {
        "id": "phFXhXL6RBeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning"
      ],
      "metadata": {
        "id": "Qs7wB8cVRW6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_tinybert(\n",
        "    model,\n",
        "    task_name,\n",
        "    train_dataloader,\n",
        "    eval_dataloader,\n",
        "    device,\n",
        "    output_mode,\n",
        "    num_labels,\n",
        "    eval_labels,\n",
        "    optimizer=None,\n",
        "    scheduler=None,\n",
        "    epochs=3\n",
        "):\n",
        "    \"\"\"\n",
        "    Fine-tune a TinyBERT model with training and validation metrics history.\n",
        "\n",
        "    Args:\n",
        "        model: The TinyBERT model to be fine-tuned.\n",
        "        task_name: Name of the task (used for metric computation).\n",
        "        train_dataloader: DataLoader for training data.\n",
        "        eval_dataloader: DataLoader for evaluation data.\n",
        "        device: Device to train on (e.g., 'cpu' or 'cuda').\n",
        "        output_mode: Output mode for the task ('classification' or 'regression').\n",
        "        num_labels: Number of labels for classification tasks.\n",
        "        eval_labels: Ground truth labels for the evaluation set.\n",
        "        optimizer: Optimizer for training (default is AdamW).\n",
        "        scheduler: Learning rate scheduler (optional).\n",
        "        epochs: Number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "        model: The fine-tuned model with a `history` attribute.\n",
        "    \"\"\"\n",
        "    # Initialize optimizer if none is provided\n",
        "    if optimizer is None:\n",
        "        optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    # Initialize or extend model's history attribute\n",
        "    if not hasattr(model, 'history'):\n",
        "        model.history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    # Move model to the specified device\n",
        "    model.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0  # To track total training loss\n",
        "        nb_train_steps = 0  # To count the number of training steps\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Training step\n",
        "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training\")):\n",
        "            # Move each tensor in the batch to the device\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch\n",
        "\n",
        "            # Zero the gradients to prevent accumulation\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            logits, _, _ = model(input_ids, segment_ids, input_mask)\n",
        "\n",
        "            # Compute loss\n",
        "            if output_mode == \"classification\":\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "            elif output_mode == \"regression\":\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "                preds = logits.squeeze()\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown output mode: {output_mode}\")\n",
        "\n",
        "            # Update metrics\n",
        "            if output_mode == \"classification\":\n",
        "                correct_predictions += (preds == label_ids).sum().item()\n",
        "                total_predictions += label_ids.size(0)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update training metrics\n",
        "            total_loss += loss.item()\n",
        "            nb_train_steps += 1\n",
        "\n",
        "        # Adjust learning rate with scheduler (if provided)\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Compute training metrics\n",
        "        avg_train_loss = total_loss / nb_train_steps\n",
        "        train_accuracy = correct_predictions / total_predictions if output_mode == \"classification\" else None\n",
        "        print(f\"Training loss: {avg_train_loss:.4f}\")\n",
        "        if train_accuracy is not None:\n",
        "            print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "        # Evaluate the model\n",
        "        eval_result = evaluate_tinybert(\n",
        "            model, task_name, eval_dataloader, device, output_mode, eval_labels, num_labels\n",
        "        )\n",
        "        avg_val_loss = eval_result['eval_loss']\n",
        "        val_accuracy = eval_result['acc']\n",
        "\n",
        "        # Print validation results\n",
        "        print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Update the model's history\n",
        "        model.history['train_loss'].append(avg_train_loss)\n",
        "        model.history['val_loss'].append(avg_val_loss)\n",
        "        if train_accuracy is not None:\n",
        "            model.history['train_acc'].append(train_accuracy)\n",
        "        model.history['val_acc'].append(val_accuracy)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "LrG1cOKoRO5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the train and evaluation dataloader\n",
        "do_lower_case = False\n",
        "data_dir = '/content/SST-2'\n",
        "processor = Sst2Processor()\n",
        "label_list = processor.get_labels()\n",
        "num_labels = len(label_list)\n",
        "max_seq_length = 128\n",
        "eval_batch_size = 32\n",
        "train_batch_size = 32\n",
        "task_name = \"sst2\"\n",
        "output_mode = \"classification\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)\n",
        "student_model.to(device)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(STUDENT_CONFIG_DIR, do_lower_case=do_lower_case)\n",
        "eval_examples = processor.get_dev_examples(data_dir)\n",
        "eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "eval_data, eval_labels = get_tensor_data(output_mode, eval_features)\n",
        "eval_sampler = SequentialSampler(eval_data)\n",
        "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
        "\n",
        "train_examples = processor.get_train_examples(data_dir)\n",
        "train_features = convert_examples_to_features(train_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "train_data, train_labels = get_tensor_data(output_mode, train_features)\n",
        "train_sampler = SequentialSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
        "\n",
        "# only train for 1 epoch - overfits fast\n",
        "student_model = train_tinybert(\n",
        "    student_model,\n",
        "    task_name,\n",
        "    train_dataloader,\n",
        "    eval_dataloader,\n",
        "    device,\n",
        "    output_mode,\n",
        "    num_labels,\n",
        "    eval_labels,\n",
        "    optimizer=None,\n",
        "    scheduler=None,\n",
        "    epochs=1\n",
        ")\n",
        "\n",
        "# SAVE MODEL\n",
        "model_path = '/content/tinyBert_sst2.pt'\n",
        "torch.save(student_model.state_dict(), model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhdRa0A7Ra7z",
        "outputId": "e3111b2b-9084-4089-daa1-e39fcf0ab2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2105/2105 [00:49<00:00, 42.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.2835\n",
            "Training accuracy: 0.8864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 148.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.2817\n",
            "Validation accuracy: 0.8842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# putting the dataset prep and training into one function\n",
        "\n",
        "def train_tinybert_sst2(student_model):\n",
        "  # building the train and evaluation dataloader\n",
        "  do_lower_case = False\n",
        "  data_dir = '/content/SST-2'\n",
        "  processor = Sst2Processor()\n",
        "  label_list = processor.get_labels()\n",
        "  num_labels = len(label_list)\n",
        "  max_seq_length = 128\n",
        "  eval_batch_size = 32\n",
        "  train_batch_size = 32\n",
        "  task_name = \"sst2\"\n",
        "  output_mode = \"classification\"\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  # student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)\n",
        "  student_model.to(device)\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained(STUDENT_CONFIG_DIR, do_lower_case=do_lower_case)\n",
        "  eval_examples = processor.get_dev_examples(data_dir)\n",
        "  eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "  eval_data, eval_labels = get_tensor_data(output_mode, eval_features)\n",
        "  eval_sampler = SequentialSampler(eval_data)\n",
        "  eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
        "\n",
        "  train_examples = processor.get_train_examples(data_dir)\n",
        "  train_features = convert_examples_to_features(train_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "  train_data, train_labels = get_tensor_data(output_mode, train_features)\n",
        "  train_sampler = SequentialSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
        "\n",
        "  # only train for 1 epoch - overfits fast\n",
        "  student_model = train_tinybert(\n",
        "      student_model,\n",
        "      task_name,\n",
        "      train_dataloader,\n",
        "      eval_dataloader,\n",
        "      device,\n",
        "      output_mode,\n",
        "      num_labels,\n",
        "      eval_labels,\n",
        "      optimizer=None,\n",
        "      scheduler=None,\n",
        "      epochs=1\n",
        "  )\n",
        "  return student_model"
      ],
      "metadata": {
        "id": "n-wkFxEqTj2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-grain Pruning"
      ],
      "metadata": {
        "id": "Yq69hGboRrQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-grain Pruning Functions"
      ],
      "metadata": {
        "id": "Hnfpatg-R95u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sparsity(tensor: torch.Tensor) -> float:\n",
        "    \"\"\"\n",
        "    calculate the sparsity of the given tensor\n",
        "        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n",
        "    \"\"\"\n",
        "    return 1 - float(tensor.count_nonzero()) / tensor.numel()\n",
        "\n",
        "\n",
        "def get_model_sparsity(model: nn.Module) -> float:\n",
        "    \"\"\"\n",
        "    calculate the sparsity of the given model\n",
        "        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n",
        "    \"\"\"\n",
        "    num_nonzeros, num_elements = 0, 0\n",
        "    for param in model.parameters():\n",
        "        num_nonzeros += param.count_nonzero()\n",
        "        num_elements += param.numel()\n",
        "    return 1 - float(num_nonzeros) / num_elements\n",
        "\n",
        "def get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n",
        "    \"\"\"\n",
        "    calculate the total number of parameters of model\n",
        "    :param count_nonzero_only: only count nonzero weights\n",
        "    \"\"\"\n",
        "    num_counted_elements = 0\n",
        "    for param in model.parameters():\n",
        "        if count_nonzero_only:\n",
        "            num_counted_elements += param.count_nonzero()\n",
        "        else:\n",
        "            num_counted_elements += param.numel()\n",
        "    return num_counted_elements\n",
        "\n",
        "\n",
        "def get_model_size(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n",
        "    \"\"\"\n",
        "    calculate the model size in bits\n",
        "    :param data_width: #bits per element\n",
        "    :param count_nonzero_only: only count nonzero weights\n",
        "    \"\"\"\n",
        "    return get_num_parameters(model, count_nonzero_only) * data_width"
      ],
      "metadata": {
        "id": "trpJLry-RnNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_grained_prune(tensor: torch.Tensor, sparsity : float) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    magnitude-based pruning for single tensor\n",
        "    :param tensor: torch.(cuda.)Tensor, weight of conv/fc layer\n",
        "    :param sparsity: float, pruning sparsity\n",
        "        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n",
        "    :return:\n",
        "        torch.(cuda.)Tensor, mask for zeros\n",
        "    \"\"\"\n",
        "    sparsity = min(max(0.0, sparsity), 1.0)\n",
        "    if sparsity == 1.0:\n",
        "        tensor.zero_()\n",
        "        return torch.zeros_like(tensor)\n",
        "    elif sparsity == 0.0:\n",
        "        return torch.ones_like(tensor)\n",
        "\n",
        "    num_elements = tensor.numel()\n",
        "\n",
        "    ##################### YOUR CODE STARTS HERE #####################\n",
        "    # Step 1: calculate the #zeros (please use round())\n",
        "    # print(\"num_elements\", num_elements)\n",
        "    # print(\"sparsity\", sparsity)\n",
        "    num_zeros = round(num_elements * sparsity)\n",
        "    # print(\"num_zeros\", num_zeros)\n",
        "    # Step 2: calculate the importance of weight\n",
        "    importance = torch.Tensor.abs(tensor)\n",
        "    # Step 3: calculate the pruning threshold\n",
        "    # print(\"importance\", torch.flatten(importance))\n",
        "    threshold = torch.kthvalue(torch.flatten(importance), num_zeros).values\n",
        "    # print(\"threshold\", threshold)\n",
        "    # Step 4: get binary mask (1 for nonzeros, 0 for zeros)\n",
        "    mask = torch.gt(importance, threshold)\n",
        "    ##################### YOUR CODE ENDS HERE #######################\n",
        "\n",
        "    # Step 5: apply mask to prune the tensor\n",
        "    tensor.mul_(mask)\n",
        "\n",
        "    return mask"
      ],
      "metadata": {
        "id": "rYC4iU2mSEEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FineGrainedPruner:\n",
        "    def __init__(self, model, sparsity_dict):\n",
        "        self.masks = FineGrainedPruner.prune(model, sparsity_dict)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def apply(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if name in self.masks:\n",
        "                param *= self.masks[name]\n",
        "\n",
        "    @staticmethod\n",
        "    @torch.no_grad()\n",
        "    def prune(model, sparsity_dict):\n",
        "        masks = dict()\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.dim() > 1: # we only prune conv and fc weights\n",
        "                masks[name] = fine_grained_prune(param, sparsity_dict[name])\n",
        "        return masks"
      ],
      "metadata": {
        "id": "4osXzo6GSESL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_size(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n",
        "    \"\"\"\n",
        "    calculate the model size in bits\n",
        "    :param data_width: #bits per element\n",
        "    :param count_nonzero_only: only count nonzero weights\n",
        "    \"\"\"\n",
        "    return get_num_parameters(model, count_nonzero_only) * data_width"
      ],
      "metadata": {
        "id": "o4WWHSnpSLf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Fine-grain pruning"
      ],
      "metadata": {
        "id": "g14uuKacSHHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the Accuracy and Model Size of Dense Model\n",
        "dense_model_accuracy = evaluate(student_model)['acc'] *100\n",
        "dense_model_size = get_model_size(student_model)\n",
        "print(f\"dense model has accuracy={dense_model_accuracy:.2f}%\")\n",
        "print(f\"dense model has size={dense_model_size/MiB:.2f} MiB\")\n",
        "\n",
        "dense_model = copy.deepcopy(student_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRcF8a2BSF5L",
        "outputId": "11f055a1-ab5f-4c59-c8cf-284f0f90b5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 145.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dense model has accuracy=88.42%\n",
            "dense model has size=55.66 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sensitivity Scan to determine optimal sparsities for each layer"
      ],
      "metadata": {
        "id": "8ethoyg6SqsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def sensitivity_scan(model, scan_step=0.1, scan_start=0.4, scan_end=1.0, verbose=True):\n",
        "    sparsities = np.arange(start=scan_start, stop=scan_end, step=scan_step)\n",
        "    accuracies = []\n",
        "    named_conv_weights = [(name, param) for (name, param) \\\n",
        "                          in model.named_parameters() if param.dim() > 1]\n",
        "    for i_layer, (name, param) in enumerate(named_conv_weights):\n",
        "        param_clone = param.detach().clone()\n",
        "        accuracy = []\n",
        "        for sparsity in tqdm(sparsities, desc=f'scanning {i_layer}/{len(named_conv_weights)} weight - {name}'):\n",
        "            fine_grained_prune(param.detach(), sparsity=sparsity)\n",
        "            acc = evaluate(model)['acc']*100\n",
        "            if verbose:\n",
        "                print(f'\\r    sparsity={sparsity:.2f}: accuracy={acc:.2f}%', end='')\n",
        "            # restore\n",
        "            param.copy_(param_clone)\n",
        "            accuracy.append(acc)\n",
        "        if verbose:\n",
        "            print(f'\\r    sparsity=[{\",\".join([\"{:.2f}\".format(x) for x in sparsities])}]: accuracy=[{\", \".join([\"{:.2f}%\".format(x) for x in accuracy])}]', end='')\n",
        "        accuracies.append(accuracy)\n",
        "    return sparsities, accuracies"
      ],
      "metadata": {
        "id": "PyUGmDHwSijC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparsities, accuracies = sensitivity_scan(\n",
        "    student_model, scan_step=0.1, scan_start=0.4, scan_end=1.0)"
      ],
      "metadata": {
        "id": "_srEJG4DSxA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def plot_sensitivity_scan(sparsities, accuracies, dense_model_accuracy):\n",
        "    lower_bound_accuracy = 100 - (100 - dense_model_accuracy) * 1.5\n",
        "    fig, axes = plt.subplots(6, int(math.ceil(len(accuracies) / 6)),figsize=(15,20), constrained_layout=True)\n",
        "    axes = axes.ravel()\n",
        "    plot_index = 0\n",
        "    for name, param in student_model.named_parameters():\n",
        "        if param.dim() > 1:\n",
        "            ax = axes[plot_index]\n",
        "            curve = ax.plot(sparsities, accuracies[plot_index])\n",
        "            line = ax.plot(sparsities, [lower_bound_accuracy] * len(sparsities))\n",
        "            ax.set_xticks(np.arange(start=0.4, stop=1.0, step=0.1))\n",
        "            ax.set_ylim(60, 95)\n",
        "            ax.set_title(\"\")\n",
        "            ax.set_xlabel('sparsity')\n",
        "            ax.set_ylabel('top-1 accuracy')\n",
        "            ax.legend([\n",
        "                'accuracy after pruning',\n",
        "                f'dense model accuracy'\n",
        "            ])\n",
        "            ax.grid(axis='x')\n",
        "            plot_index += 1\n",
        "    fig.suptitle('Sensitivity Curves: Validation Accuracy vs. Pruning Sparsity (for each layer with dims > 1)', fontsize = 16)\n",
        "    fig.tight_layout()\n",
        "    fig.subplots_adjust(top=0.96)\n",
        "    plt.show()\n",
        "\n",
        "plot_sensitivity_scan(sparsities, accuracies, dense_model_accuracy)"
      ],
      "metadata": {
        "id": "w5PFoLalSzLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimal Pruned Model"
      ],
      "metadata": {
        "id": "E8bvJnG5S6KH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense_model = copy.deepcopy(student_model)"
      ],
      "metadata": {
        "id": "i7CMFU7GS71S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build sparsity dictionary\n",
        "# TODO: fill in values based on results of sensitivity testing\n",
        "sparsity_dict = {\n",
        "'bert.embeddings.word_embeddings.weight':0.5,\n",
        "'bert.embeddings.position_embeddings.weight':0.8,\n",
        "'bert.embeddings.token_type_embeddings.weight':0.6,\n",
        "'bert.encoder.layer.0.attention.self.query.weight':0.9,\n",
        "'bert.encoder.layer.0.attention.self.key.weight':0.9,\n",
        "'bert.encoder.layer.0.attention.self.value.weight':0.6,\n",
        "'bert.encoder.layer.0.attention.output.dense.weight':0.5,\n",
        "'bert.encoder.layer.0.intermediate.dense.weight':0.5,\n",
        "'bert.encoder.layer.0.output.dense.weight':0.5,\n",
        "'bert.encoder.layer.1.attention.self.query.weight':0.5,\n",
        "'bert.encoder.layer.1.attention.self.key.weight':0.6,\n",
        "'bert.encoder.layer.1.attention.self.value.weight':0.9,\n",
        "'bert.encoder.layer.1.attention.output.dense.weight':0.7,\n",
        "'bert.encoder.layer.1.intermediate.dense.weight':0.5,\n",
        "'bert.encoder.layer.1.output.dense.weight':0.7,\n",
        "'bert.encoder.layer.2.attention.self.query.weight':0.6,\n",
        "'bert.encoder.layer.2.attention.self.key.weight':0.5,\n",
        "'bert.encoder.layer.2.attention.self.value.weight':0.9,\n",
        "'bert.encoder.layer.2.attention.output.dense.weight':0.9,\n",
        "'bert.encoder.layer.2.intermediate.dense.weight':0.9,\n",
        "'bert.encoder.layer.2.output.dense.weight':0.9,\n",
        "'bert.encoder.layer.3.attention.self.query.weight':0.9,\n",
        "'bert.encoder.layer.3.attention.self.key.weight':0.7,\n",
        "'bert.encoder.layer.3.attention.self.value.weight':0.6,\n",
        "'bert.encoder.layer.3.attention.output.dense.weight':0.9,\n",
        "'bert.encoder.layer.3.intermediate.dense.weight':0.9,\n",
        "'bert.encoder.layer.3.output.dense.weight':0.7,\n",
        "'bert.pooler.dense.weight':0.8,\n",
        "'classifier.weight':0.9,\n",
        "'fit_dense.weight':0.9,\n",
        "}"
      ],
      "metadata": {
        "id": "PrZRQszLS89D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pruner = FineGrainedPruner(student_model, sparsity_dict)\n",
        "\n",
        "sparse_model_size = get_model_size(student_model, count_nonzero_only=True)\n",
        "print(f\"Sparse model has size={sparse_model_size / MiB:.2f} MiB = {sparse_model_size / dense_model_size * 100:.2f}% of dense model size\")\n",
        "sparse_model_accuracy = evaluate(student_model)['acc']*100\n",
        "print(\"\\n\")\n",
        "print(f\"Sparse model has accuracy={sparse_model_accuracy:.2f}% before fintuning\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAPNXhZRS_hb",
        "outputId": "fcfec027-03c9-4c21-d58d-324a9d0a2ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparse model has size=23.58 MiB = 42.36% of dense model size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 145.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Sparse model has accuracy=65.94% before fintuning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning the fine-grain pruned model"
      ],
      "metadata": {
        "id": "UQKxR5n2TMnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student_model = train_tinybert_sst2(student_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8a8aTDdTAKu",
        "outputId": "2d4c6902-8996-4172-b02d-34905fd87162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2105/2105 [00:49<00:00, 42.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.2284\n",
            "Training accuracy: 0.9136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 145.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.3839\n",
            "Validation accuracy: 0.8532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots for finegrain pruning - TODO"
      ],
      "metadata": {
        "id": "uT62Cv-dUUzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Channel Pruning - TODO"
      ],
      "metadata": {
        "id": "CQKPBBPIT_g4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v6qniuz5T3ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-means quantization"
      ],
      "metadata": {
        "id": "psAo7go4UDg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-means quantization functions"
      ],
      "metadata": {
        "id": "bytVEtQ1Ugox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "Codebook = namedtuple('Codebook', ['centroids', 'labels'])"
      ],
      "metadata": {
        "id": "PaS374v5Udbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fast_pytorch_kmeans import KMeans\n",
        "\n",
        "def k_means_quantize(fp32_tensor: torch.Tensor, bitwidth=4, codebook=None):\n",
        "    \"\"\"\n",
        "    quantize tensor using k-means clustering\n",
        "    :param fp32_tensor:\n",
        "    :param bitwidth: [int] quantization bit width, default=4\n",
        "    :param codebook: [Codebook] (the cluster centroids, the cluster label tensor)\n",
        "    :return:\n",
        "        [Codebook = (centroids, labels)]\n",
        "            centroids: [torch.(cuda.)FloatTensor] the cluster centroids\n",
        "            labels: [torch.(cuda.)LongTensor] cluster label tensor\n",
        "    \"\"\"\n",
        "    if codebook is None:\n",
        "        ############### YOUR CODE STARTS HERE ###############\n",
        "        # get number of clusters based on the quantization precision\n",
        "        # hint: one line of code\n",
        "        n_clusters = 2**bitwidth\n",
        "        ############### YOUR CODE ENDS HERE #################\n",
        "        # use k-means to get the quantization centroids\n",
        "        kmeans = KMeans(n_clusters=n_clusters, mode='euclidean', verbose=0)\n",
        "        labels = kmeans.fit_predict(fp32_tensor.view(-1, 1)).to(torch.long)\n",
        "        centroids = kmeans.centroids.to(torch.float).view(-1)\n",
        "        codebook = Codebook(centroids, labels)\n",
        "    ############### YOUR CODE STARTS HERE ###############\n",
        "    # decode the codebook into k-means quantized tensor for inference\n",
        "    # hint: one line of code\n",
        "    quantized_tensor = codebook.centroids[codebook.labels].view_as(fp32_tensor)\n",
        "    ############### YOUR CODE ENDS HERE #################\n",
        "    fp32_tensor.set_(quantized_tensor.view_as(fp32_tensor))\n",
        "    return codebook"
      ],
      "metadata": {
        "id": "1sZX-fC2Ul-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_codebook(fp32_tensor: torch.Tensor, codebook: Codebook):\n",
        "    \"\"\"\n",
        "    update the centroids in the codebook using updated fp32_tensor\n",
        "    :param fp32_tensor: [torch.(cuda.)Tensor]\n",
        "    :param codebook: [Codebook] (the cluster centroids, the cluster label tensor)\n",
        "    \"\"\"\n",
        "    n_clusters = codebook.centroids.numel()\n",
        "    fp32_tensor = fp32_tensor.view(-1)\n",
        "    for k in range(n_clusters):\n",
        "    ############### YOUR CODE STARTS HERE ###############\n",
        "        # hint: one line of code\n",
        "        # codebook.centroids[k] = torch.mean(fp32_tensor)\n",
        "        # print(\"length of codebook labels:\", len(codebook.labels))\n",
        "        # print(\"length of fp32_tensor:\", len(fp32_tensor))\n",
        "        codebook.centroids[k] = torch.mean(fp32_tensor[codebook.labels == k])\n",
        "    ############### YOUR CODE ENDS HERE #################"
      ],
      "metadata": {
        "id": "Eg1LtlG6Un5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import parameter\n",
        "class KMeansQuantizer:\n",
        "    def __init__(self, model : nn.Module, bitwidth=4):\n",
        "        self.codebook = KMeansQuantizer.quantize(model, bitwidth)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def apply(self, model, update_centroids):\n",
        "        for name, param in model.named_parameters():\n",
        "            if name in self.codebook:\n",
        "                if update_centroids:\n",
        "                    update_codebook(param, codebook=self.codebook[name])\n",
        "                self.codebook[name] = k_means_quantize(\n",
        "                    param, codebook=self.codebook[name])\n",
        "\n",
        "    @staticmethod\n",
        "    @torch.no_grad()\n",
        "    def quantize(model: nn.Module, bitwidth=4):\n",
        "        codebook = dict()\n",
        "        if isinstance(bitwidth, dict):\n",
        "            for name, param in model.named_parameters():\n",
        "                if name in bitwidth:\n",
        "                    codebook[name] = k_means_quantize(param, bitwidth=bitwidth[name])\n",
        "        else:\n",
        "            for name, param in model.named_parameters():\n",
        "                if param.dim() > 1:\n",
        "                    codebook[name] = k_means_quantize(param, bitwidth=bitwidth)\n",
        "        return codebook"
      ],
      "metadata": {
        "id": "DiS6sZ3SUqsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test k-means quantization"
      ],
      "metadata": {
        "id": "9KXkNIKSUy09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "quantizers = dict()\n",
        "bitwidths = [8, 4, 2]\n",
        "accs = []\n",
        "sizes = []\n",
        "for bitwidth in bitwidths:\n",
        "    # student_model = load_original_model()\n",
        "    # student_model.to(device)\n",
        "    # student_model = nn.DataParallel(student_model)\n",
        "    student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)\n",
        "\n",
        "    print(f'k-means quantizing model into {bitwidth} bits')\n",
        "    quantizer = KMeansQuantizer(student_model, bitwidth)\n",
        "    quantized_model_size = get_model_size(student_model, bitwidth)\n",
        "    print(f\"    {bitwidth}-bit k-means quantized model has size={quantized_model_size/MiB:.2f} MiB\")\n",
        "    sizes.append(quantized_model_size)\n",
        "    quantized_model_accuracy = evaluate(student_model)['acc'] *100\n",
        "    accs.append(quantized_model_accuracy)\n",
        "    print(f\"    {bitwidth}-bit k-means quantized model has accuracy={quantized_model_accuracy:.2f}%\")\n",
        "    quantizers[bitwidth] = quantizer\n",
        "\n",
        "plt.plot(bitwidths, accs)\n",
        "plt.xlabel('bitwidth')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "eNKFPDoQUrAE",
        "outputId": "bea1ae39-fb69-4d96-f195-80526207a3d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-means quantizing model into 8 bits\n",
            "    8-bit k-means quantized model has size=13.92 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 127.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    8-bit k-means quantized model has accuracy=50.92%\n",
            "k-means quantizing model into 4 bits\n",
            "    4-bit k-means quantized model has size=6.96 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 130.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    4-bit k-means quantized model has accuracy=50.80%\n",
            "k-means quantizing model into 2 bits\n",
            "    2-bit k-means quantized model has size=3.48 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 124.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    2-bit k-means quantized model has accuracy=49.08%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save accs, sizes, and bitwidths to a pickle file\n",
        "import pickle\n",
        "res_dict = {'accs': accs, 'sizes': sizes, 'bitwidths': bitwidths}\n",
        "file_name = \"quant_no_finetuning_data.pkl\"\n",
        "with open(f'/content/{file_name}', 'wb') as f:\n",
        "    pickle.dump(res_dict, f)"
      ],
      "metadata": {
        "id": "W4MBCpQxX-6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetuning quantized model"
      ],
      "metadata": {
        "id": "Yw9V41ZZVCeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need a new training function for finetuning the quantized model because after each epoch we have to re-quantize the weights. The new method is modified only by additionally taking in the `quantizer` as a parameter and calling `quantizer.apply` after each epoch."
      ],
      "metadata": {
        "id": "Pk4rbsHkXZDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### finetuning quantized model methods"
      ],
      "metadata": {
        "id": "dZ6ZDEGvaFIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_quantized_tinybert(\n",
        "    model,\n",
        "    quantizer,\n",
        "    task_name,\n",
        "    train_dataloader,\n",
        "    eval_dataloader,\n",
        "    device,\n",
        "    output_mode,\n",
        "    num_labels,\n",
        "    eval_labels,\n",
        "    optimizer=None,\n",
        "    scheduler=None,\n",
        "    epochs=3\n",
        "):\n",
        "    \"\"\"\n",
        "    Fine-tune a TinyBERT model with training and validation metrics history.\n",
        "\n",
        "    Args:\n",
        "        model: The TinyBERT model to be fine-tuned.\n",
        "        task_name: Name of the task (used for metric computation).\n",
        "        train_dataloader: DataLoader for training data.\n",
        "        eval_dataloader: DataLoader for evaluation data.\n",
        "        device: Device to train on (e.g., 'cpu' or 'cuda').\n",
        "        output_mode: Output mode for the task ('classification' or 'regression').\n",
        "        num_labels: Number of labels for classification tasks.\n",
        "        eval_labels: Ground truth labels for the evaluation set.\n",
        "        optimizer: Optimizer for training (default is AdamW).\n",
        "        scheduler: Learning rate scheduler (optional).\n",
        "        epochs: Number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "        model: The fine-tuned model with a `history` attribute.\n",
        "    \"\"\"\n",
        "    # Initialize optimizer if none is provided\n",
        "    if optimizer is None:\n",
        "        optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    # Initialize or extend model's history attribute\n",
        "    if not hasattr(model, 'history'):\n",
        "        model.history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    # Move model to the specified device\n",
        "    model.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0  # To track total training loss\n",
        "        nb_train_steps = 0  # To count the number of training steps\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Training step\n",
        "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training\")):\n",
        "            # Move each tensor in the batch to the device\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch\n",
        "\n",
        "            # Zero the gradients to prevent accumulation\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            logits, _, _ = model(input_ids, segment_ids, input_mask)\n",
        "\n",
        "            # Compute loss\n",
        "            if output_mode == \"classification\":\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "            elif output_mode == \"regression\":\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "                preds = logits.squeeze()\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown output mode: {output_mode}\")\n",
        "\n",
        "            # Update metrics\n",
        "            if output_mode == \"classification\":\n",
        "                correct_predictions += (preds == label_ids).sum().item()\n",
        "                total_predictions += label_ids.size(0)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # apply the quantization\n",
        "            quantizer.apply(model, update_centroids=False)\n",
        "\n",
        "            # Update training metrics\n",
        "            total_loss += loss.item()\n",
        "            nb_train_steps += 1\n",
        "\n",
        "        # Adjust learning rate with scheduler (if provided)\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Compute training metrics\n",
        "        avg_train_loss = total_loss / nb_train_steps\n",
        "        train_accuracy = correct_predictions / total_predictions if output_mode == \"classification\" else None\n",
        "        print(f\"Training loss: {avg_train_loss:.4f}\")\n",
        "        if train_accuracy is not None:\n",
        "            print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "        # Evaluate the model\n",
        "        eval_result = evaluate_tinybert(\n",
        "            model, task_name, eval_dataloader, device, output_mode, eval_labels, num_labels\n",
        "        )\n",
        "        avg_val_loss = eval_result['eval_loss']\n",
        "        val_accuracy = eval_result['acc']\n",
        "\n",
        "        # Print validation results\n",
        "        print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Update the model's history\n",
        "        model.history['train_loss'].append(avg_train_loss)\n",
        "        model.history['val_loss'].append(avg_val_loss)\n",
        "        if train_accuracy is not None:\n",
        "            model.history['train_acc'].append(train_accuracy)\n",
        "        model.history['val_acc'].append(val_accuracy)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Ssdf82I2U3Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# putting the dataset prep and training into one function\n",
        "\n",
        "def train_quantized_tinybert_sst2(student_model, quantizer):\n",
        "  # building the train and evaluation dataloader\n",
        "  do_lower_case = False\n",
        "  data_dir = '/content/SST-2'\n",
        "  processor = Sst2Processor()\n",
        "  label_list = processor.get_labels()\n",
        "  num_labels = len(label_list)\n",
        "  max_seq_length = 128\n",
        "  eval_batch_size = 32\n",
        "  train_batch_size = 32\n",
        "  task_name = \"sst2\"\n",
        "  output_mode = \"classification\"\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  # student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)\n",
        "  student_model.to(device)\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained(STUDENT_CONFIG_DIR, do_lower_case=do_lower_case)\n",
        "  eval_examples = processor.get_dev_examples(data_dir)\n",
        "  eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "  eval_data, eval_labels = get_tensor_data(output_mode, eval_features)\n",
        "  eval_sampler = SequentialSampler(eval_data)\n",
        "  eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
        "\n",
        "  train_examples = processor.get_train_examples(data_dir)\n",
        "  train_features = convert_examples_to_features(train_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "  train_data, train_labels = get_tensor_data(output_mode, train_features)\n",
        "  train_sampler = SequentialSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
        "\n",
        "  # only train for 1 epoch - overfits fast\n",
        "  student_model = train_quantized_tinybert(\n",
        "      student_model,\n",
        "      quantizer,\n",
        "      task_name,\n",
        "      train_dataloader,\n",
        "      eval_dataloader,\n",
        "      device,\n",
        "      output_mode,\n",
        "      num_labels,\n",
        "      eval_labels,\n",
        "      optimizer=None,\n",
        "      scheduler=None,\n",
        "      epochs=1\n",
        "  )\n",
        "  return student_model"
      ],
      "metadata": {
        "id": "KrquyJ-YZ9lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the Finetuning"
      ],
      "metadata": {
        "id": "OjWl1DoKaRbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "quantizers = dict()\n",
        "bitwidths = [8, 4, 2]\n",
        "accs = []\n",
        "sizes = []\n",
        "for bitwidth in bitwidths:\n",
        "    # student_model = load_original_model()\n",
        "    # student_model.to(device)\n",
        "    # student_model = nn.DataParallel(student_model)\n",
        "    student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)\n",
        "    student_model.to(device)\n",
        "\n",
        "    print(f'k-means quantizing model into {bitwidth} bits')\n",
        "    quantizer = KMeansQuantizer(student_model, bitwidth)\n",
        "\n",
        "    # finetune quantized model\n",
        "    print(f\"FINETUNING {bitwidth}-bit model\")\n",
        "    student_model = train_quantized_tinybert_sst2(student_model, quantizer)\n",
        "\n",
        "    quantized_model_size = get_model_size(student_model, bitwidth)\n",
        "    print(f\"    {bitwidth}-bit k-means quantized model has size={quantized_model_size/MiB:.2f} MiB\")\n",
        "    sizes.append(quantized_model_size)\n",
        "    quantized_model_accuracy = evaluate(student_model)['acc'] *100\n",
        "    accs.append(quantized_model_accuracy)\n",
        "    print(f\"    {bitwidth}-bit k-means quantized model has accuracy={quantized_model_accuracy:.2f}%\")\n",
        "    quantizers[bitwidth] = quantizer\n",
        "\n",
        "plt.plot(bitwidths, accs)\n",
        "plt.xlabel('bitwidth')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5fow9ecOaU2U",
        "outputId": "815e39e4-bc96-46c3-daaf-dc9eb0d96e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Pretrained-Language-Model/TinyBERT/transformer/modeling.py:696: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(weights_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-means quantizing model into 8 bits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2105/2105 [00:51<00:00, 40.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.6609\n",
            "Training accuracy: 0.7739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 145.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.6407\n",
            "Validation accuracy: 0.7913\n",
            "FINETUNING 8-bit model\n",
            "    8-bit k-means quantized model has size=13.92 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 145.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    8-bit k-means quantized model has accuracy=79.13%\n",
            "k-means quantizing model into 4 bits\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2105/2105 [00:52<00:00, 40.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.6718\n",
            "Training accuracy: 0.5580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 147.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.6546\n",
            "Validation accuracy: 0.5837\n",
            "FINETUNING 4-bit model\n",
            "    4-bit k-means quantized model has size=6.96 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 143.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    4-bit k-means quantized model has accuracy=58.37%\n",
            "k-means quantizing model into 2 bits\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2105/2105 [00:51<00:00, 40.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.6870\n",
            "Training accuracy: 0.5578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 146.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.6924\n",
            "Validation accuracy: 0.5092\n",
            "FINETUNING 2-bit model\n",
            "    2-bit k-means quantized model has size=3.48 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 145.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    2-bit k-means quantized model has accuracy=50.92%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save accs, sizes, and bitwidths to a pickle file\n",
        "import pickle\n",
        "res_dict = {'accs': accs, 'sizes': sizes, 'bitwidths': bitwidths}\n",
        "file_name = \"quant_WITH_finetuning_data.pkl\"\n",
        "with open(f'/content/{file_name}', 'wb') as f:\n",
        "    pickle.dump(res_dict, f)"
      ],
      "metadata": {
        "id": "UKHx19_ja1wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pruning AND Quantization Together"
      ],
      "metadata": {
        "id": "aqRwXwO4fJzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply Pruning and Quantization without Finetuning"
      ],
      "metadata": {
        "id": "3QOUCL7JiE2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "quantizers = dict()\n",
        "bitwidths = [8, 4, 2]\n",
        "accs = []\n",
        "sparse_sizes = []\n",
        "final_sizes = []\n",
        "for bitwidth in bitwidths:\n",
        "    # student_model = load_original_model()\n",
        "    # student_model.to(device)\n",
        "    # student_model = nn.DataParallel(student_model)\n",
        "    student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)\n",
        "\n",
        "    print(\"pruning...\")\n",
        "    pruner = FineGrainedPruner(student_model, sparsity_dict)\n",
        "    # before quantizing, the bitwidth is 32\n",
        "    sparse_model_size = get_model_size(student_model, data_width=32, count_nonzero_only=True)\n",
        "    sparse_sizes.append(sparse_model_size)\n",
        "    print(f\"  pruned model has size={sparse_model_size/MiB:.2f} MiB\")\n",
        "\n",
        "    print(f'k-means quantizing model into {bitwidth} bits')\n",
        "    quantizer = KMeansQuantizer(student_model, bitwidth)\n",
        "    quantized_model_size = get_model_size(student_model, data_width=bitwidth, count_nonzero_only=True)\n",
        "    final_sizes.append(quantized_model_size)\n",
        "    print(f\"    pruned {bitwidth}-bit k-means quantized model has size={quantized_model_size/MiB:.2f} MiB\")\n",
        "\n",
        "    quantized_model_accuracy = evaluate(student_model)['acc'] *100\n",
        "    accs.append(quantized_model_accuracy)\n",
        "    print(f\"    pruned {bitwidth}-bit k-means quantized model has accuracy={quantized_model_accuracy:.2f}%\")\n",
        "    quantizers[bitwidth] = quantizer\n",
        "\n",
        "plt.plot(bitwidths, accs)\n",
        "plt.xlabel('bitwidth')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "F7PIzJExiKfD",
        "outputId": "ab9794d2-2f3d-4ff6-ccbc-b25ca11af782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Pretrained-Language-Model/TinyBERT/transformer/modeling.py:696: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(weights_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pruning...\n",
            "  pruned model has size=23.58 MiB\n",
            "k-means quantizing model into 8 bits\n",
            "    pruned 8-bit k-means quantized model has size=5.89 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 123.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    pruned 8-bit k-means quantized model has accuracy=50.92%\n",
            "pruning...\n",
            "  pruned model has size=23.58 MiB\n",
            "k-means quantizing model into 4 bits\n",
            "    pruned 4-bit k-means quantized model has size=2.99 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 124.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    pruned 4-bit k-means quantized model has accuracy=50.92%\n",
            "pruning...\n",
            "  pruned model has size=23.58 MiB\n",
            "k-means quantizing model into 2 bits\n",
            "    pruned 2-bit k-means quantized model has size=3.21 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 124.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    pruned 2-bit k-means quantized model has accuracy=49.08%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save accs, sizes, and bitwidths to a pickle file\n",
        "import pickle\n",
        "res_dict = {'accs': accs, 'sparse_sizes': sparse_sizes, 'final_sizes': final_sizes, 'bitwidths': bitwidths}\n",
        "file_name = \"prune_and_quant_NO_finetuning_data.pkl\"\n",
        "with open(f'/content/{file_name}', 'wb') as f:\n",
        "    pickle.dump(res_dict, f)"
      ],
      "metadata": {
        "id": "9RJBfvLTifRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## finetuning pruned+quantized model functions"
      ],
      "metadata": {
        "id": "7xJEuGHGf2jV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When finetuning a pruned and quantized model, we need to apply both the pruner and quantizer after each epoch."
      ],
      "metadata": {
        "id": "iM_IIcscfuAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_pruned_quantized_tinybert(\n",
        "    model,\n",
        "    quantizer,\n",
        "    pruner,\n",
        "    task_name,\n",
        "    train_dataloader,\n",
        "    eval_dataloader,\n",
        "    device,\n",
        "    output_mode,\n",
        "    num_labels,\n",
        "    eval_labels,\n",
        "    optimizer=None,\n",
        "    scheduler=None,\n",
        "    epochs=3\n",
        "):\n",
        "    \"\"\"\n",
        "    Fine-tune a TinyBERT model with training and validation metrics history.\n",
        "\n",
        "    Args:\n",
        "        model: The TinyBERT model to be fine-tuned.\n",
        "        task_name: Name of the task (used for metric computation).\n",
        "        train_dataloader: DataLoader for training data.\n",
        "        eval_dataloader: DataLoader for evaluation data.\n",
        "        device: Device to train on (e.g., 'cpu' or 'cuda').\n",
        "        output_mode: Output mode for the task ('classification' or 'regression').\n",
        "        num_labels: Number of labels for classification tasks.\n",
        "        eval_labels: Ground truth labels for the evaluation set.\n",
        "        optimizer: Optimizer for training (default is AdamW).\n",
        "        scheduler: Learning rate scheduler (optional).\n",
        "        epochs: Number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "        model: The fine-tuned model with a `history` attribute.\n",
        "    \"\"\"\n",
        "    # Initialize optimizer if none is provided\n",
        "    if optimizer is None:\n",
        "        optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    # Initialize or extend model's history attribute\n",
        "    if not hasattr(model, 'history'):\n",
        "        model.history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    # Move model to the specified device\n",
        "    model.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0  # To track total training loss\n",
        "        nb_train_steps = 0  # To count the number of training steps\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Training step\n",
        "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training\")):\n",
        "            # Move each tensor in the batch to the device\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch\n",
        "\n",
        "            # Zero the gradients to prevent accumulation\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            logits, _, _ = model(input_ids, segment_ids, input_mask)\n",
        "\n",
        "            # Compute loss\n",
        "            if output_mode == \"classification\":\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "            elif output_mode == \"regression\":\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
        "                preds = logits.squeeze()\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown output mode: {output_mode}\")\n",
        "\n",
        "            # Update metrics\n",
        "            if output_mode == \"classification\":\n",
        "                correct_predictions += (preds == label_ids).sum().item()\n",
        "                total_predictions += label_ids.size(0)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # apply the pruning and quantization\n",
        "            pruner.apply(model)\n",
        "            quantizer.apply(model, update_centroids=True)\n",
        "\n",
        "            # Update training metrics\n",
        "            total_loss += loss.item()\n",
        "            nb_train_steps += 1\n",
        "\n",
        "        # Adjust learning rate with scheduler (if provided)\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Compute training metrics\n",
        "        avg_train_loss = total_loss / nb_train_steps\n",
        "        train_accuracy = correct_predictions / total_predictions if output_mode == \"classification\" else None\n",
        "        print(f\"Training loss: {avg_train_loss:.4f}\")\n",
        "        if train_accuracy is not None:\n",
        "            print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "        # Evaluate the model\n",
        "        eval_result = evaluate_tinybert(\n",
        "            model, task_name, eval_dataloader, device, output_mode, eval_labels, num_labels\n",
        "        )\n",
        "        avg_val_loss = eval_result['eval_loss']\n",
        "        val_accuracy = eval_result['acc']\n",
        "\n",
        "        # Print validation results\n",
        "        print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Update the model's history\n",
        "        model.history['train_loss'].append(avg_train_loss)\n",
        "        model.history['val_loss'].append(avg_val_loss)\n",
        "        if train_accuracy is not None:\n",
        "            model.history['train_acc'].append(train_accuracy)\n",
        "        model.history['val_acc'].append(val_accuracy)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Ed60ycHMcBAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# putting the dataset prep and training into one function\n",
        "\n",
        "def train_pruned_quantized_tinybert_sst2(student_model, quantizer, pruner):\n",
        "  # building the train and evaluation dataloader\n",
        "  do_lower_case = False\n",
        "  data_dir = '/content/SST-2'\n",
        "  processor = Sst2Processor()\n",
        "  label_list = processor.get_labels()\n",
        "  num_labels = len(label_list)\n",
        "  max_seq_length = 128\n",
        "  eval_batch_size = 32\n",
        "  train_batch_size = 32\n",
        "  task_name = \"sst2\"\n",
        "  output_mode = \"classification\"\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  # student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)\n",
        "  student_model.to(device)\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained(STUDENT_CONFIG_DIR, do_lower_case=do_lower_case)\n",
        "  eval_examples = processor.get_dev_examples(data_dir)\n",
        "  eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "  eval_data, eval_labels = get_tensor_data(output_mode, eval_features)\n",
        "  eval_sampler = SequentialSampler(eval_data)\n",
        "  eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
        "\n",
        "  train_examples = processor.get_train_examples(data_dir)\n",
        "  train_features = convert_examples_to_features(train_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
        "  train_data, train_labels = get_tensor_data(output_mode, train_features)\n",
        "  train_sampler = SequentialSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
        "\n",
        "  # only train for 1 epoch - overfits fast\n",
        "  student_model = train_pruned_quantized_tinybert(\n",
        "      student_model,\n",
        "      quantizer,\n",
        "      pruner,\n",
        "      task_name,\n",
        "      train_dataloader,\n",
        "      eval_dataloader,\n",
        "      device,\n",
        "      output_mode,\n",
        "      num_labels,\n",
        "      eval_labels,\n",
        "      optimizer=None,\n",
        "      scheduler=None,\n",
        "      epochs=1\n",
        "  )\n",
        "  return student_model"
      ],
      "metadata": {
        "id": "dmeBMsL0gSVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## run finetuning on pruned and quantized model"
      ],
      "metadata": {
        "id": "SurXNlbvgf6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "quantizers = dict()\n",
        "bitwidths = [8, 4, 2]\n",
        "accs = []\n",
        "sizes = []\n",
        "sparse_sizes = []\n",
        "final_sizes = []\n",
        "for bitwidth in bitwidths:\n",
        "    # student_model = load_original_model()\n",
        "    # student_model.to(device)\n",
        "    # student_model = nn.DataParallel(student_model)\n",
        "    student_model = TinyBertForSequenceClassification.from_pretrained(STUDENT_CONFIG_DIR, num_labels=num_labels)\n",
        "    student_model.to(device)\n",
        "\n",
        "    print(\"pruning...\")\n",
        "    pruner = FineGrainedPruner(student_model, sparsity_dict)\n",
        "    # before quantizing, the bitwidth is 32\n",
        "    sparse_model_size = get_model_size(student_model, data_width=32, count_nonzero_only=True)\n",
        "    sparse_sizes.append(sparse_model_size)\n",
        "    print(f\"  pruned model has size={sparse_model_size/MiB:.2f} MiB\")\n",
        "\n",
        "    print(f'k-means quantizing model into {bitwidth} bits')\n",
        "    quantizer = KMeansQuantizer(student_model, bitwidth)\n",
        "    quantized_model_size = get_model_size(student_model, data_width=bitwidth, count_nonzero_only=True)\n",
        "    final_sizes.append(quantized_model_size)\n",
        "    print(f\"    pruned {bitwidth}-bit k-means quantized model has size={quantized_model_size/MiB:.2f} MiB\")\n",
        "\n",
        "    # finetune quantized model\n",
        "    print(f\"FINETUNING pruned {bitwidth}-bit model\")\n",
        "    student_model = train_pruned_quantized_tinybert_sst2(student_model, quantizer, pruner)\n",
        "\n",
        "    quantized_model_accuracy = evaluate(student_model)['acc'] *100\n",
        "    accs.append(quantized_model_accuracy)\n",
        "    print(f\"    pruned {bitwidth}-bit k-means quantized model has accuracy={quantized_model_accuracy:.2f}%\")\n",
        "    quantizers[bitwidth] = quantizer\n",
        "\n",
        "plt.plot(bitwidths, accs)\n",
        "plt.xlabel('bitwidth')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wwD9fDyHgele",
        "outputId": "f1381b0e-de82-4065-ff00-72c16a52aae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Pretrained-Language-Model/TinyBERT/transformer/modeling.py:696: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(weights_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pruning...\n",
            "  pruned model has size=23.58 MiB\n",
            "k-means quantizing model into 8 bits\n",
            "    pruned 8-bit k-means quantized model has size=5.89 MiB\n",
            "FINETUNING pruned 8-bit model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2105/2105 [28:34<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.6877\n",
            "Training accuracy: 0.5554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 146.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.6935\n",
            "Validation accuracy: 0.5092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 145.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    pruned 8-bit k-means quantized model has accuracy=50.92%\n",
            "pruning...\n",
            "  pruned model has size=23.58 MiB\n",
            "k-means quantizing model into 4 bits\n",
            "    pruned 4-bit k-means quantized model has size=3.21 MiB\n",
            "FINETUNING pruned 4-bit model\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2105/2105 [02:45<00:00, 12.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.6877\n",
            "Training accuracy: 0.5578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 145.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.6945\n",
            "Validation accuracy: 0.5092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 143.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    pruned 4-bit k-means quantized model has accuracy=50.92%\n",
            "pruning...\n",
            "  pruned model has size=23.58 MiB\n",
            "k-means quantizing model into 2 bits\n",
            "    pruned 2-bit k-means quantized model has size=3.14 MiB\n",
            "FINETUNING pruned 2-bit model\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2105/2105 [01:25<00:00, 24.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.6906\n",
            "Training accuracy: 0.5575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 145.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.6934\n",
            "Validation accuracy: 0.5092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 146.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    pruned 2-bit k-means quantized model has accuracy=50.92%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save accs, sizes, and bitwidths to a pickle file\n",
        "import pickle\n",
        "res_dict = {'accs': accs, 'sparse_sizes': sparse_sizes, 'final_sizes': final_sizes, 'bitwidths': bitwidths}\n",
        "file_name = \"prune_and_quant_WITH_finetuning_data.pkl\"\n",
        "with open(f'/content/{file_name}', 'wb') as f:\n",
        "    pickle.dump(res_dict, f)"
      ],
      "metadata": {
        "id": "YK3rCCrAkV7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BtLeLiY8ugKq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}